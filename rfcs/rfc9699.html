<!DOCTYPE html>
<html lang="en" class="RFC">
<head>
<meta charset="utf-8">
<meta content="Common,Latin" name="scripts">
<meta content="initial-scale=1.0" name="viewport">
<title>RFC 9699: Use Case for an Extended Reality Application on Edge Computing Infrastructure</title>
<meta content="Renan Krishna" name="author">
<meta content="Akbar Rahman" name="author">
<meta content="
       This document explores the issues involved in the use of edge
      computing resources to operationalize a media use case that involves an
      Extended Reality (XR) application. In particular, this document
      discusses an XR application that can run on devices having different
      form factors (such as different physical sizes and shapes) and needs edge
      computing resources to mitigate the effect of problems such as the need
      to support interactive communication requiring low latency, limited
      battery power, and heat dissipation from those devices.  This document
      also discusses the expected behavior of XR applications, which can be
      used to manage traffic, and the service requirements for XR applications
      to be able to run on the network. Network operators who are interested
      in providing edge computing resources to operationalize the requirements
      of such applications are the intended audience for this document.
       
    " name="description">
<meta content="xml2rfc 3.25.0" name="generator">
<meta content="9699" name="rfc.number">
<!-- Generator version information:
  xml2rfc 3.25.0
    Python 3.9.15
    ConfigArgParse 1.5.3
    google-i18n-address 3.0.0
    intervaltree 3.1.0
    Jinja2 3.1.2
    lxml 5.3.0
    platformdirs 3.8.0
    pycountry 22.3.5
    pydyf 0.10.0
    PyYAML 6.0
    requests 2.28.0
    setuptools 44.1.1
    wcwidth 0.2.5
    weasyprint 62.3
-->
<link href="rfc9699.xml" rel="alternate" type="application/rfc+xml">
<link href="#copyright" rel="license">
<style type="text/css">/*

  NOTE: Changes at the bottom of this file overrides some earlier settings.

  Once the style has stabilized and has been adopted as an official RFC style,
  this can be consolidated so that style settings occur only in one place, but
  for now the contents of this file consists first of the initial CSS work as
  provided to the RFC Formatter (xml2rfc) work, followed by itemized and
  commented changes found necessary during the development of the v3
  formatters.

*/

/* fonts */
@import url('https://fonts.googleapis.com/css?family=Noto+Sans'); /* Sans-serif */
@import url('https://fonts.googleapis.com/css?family=Noto+Serif'); /* Serif (print) */
@import url('https://fonts.googleapis.com/css?family=Roboto+Mono'); /* Monospace */

:root {
  --font-sans: 'Noto Sans', Arial, Helvetica, sans-serif;
  --font-serif: 'Noto Serif', 'Times', 'Times New Roman', serif;
  --font-mono: 'Roboto Mono', Courier, 'Courier New', monospace;
}

@viewport {
  zoom: 1.0;
}
@-ms-viewport {
  width: extend-to-zoom;
  zoom: 1.0;
}
/* general and mobile first */
html {
}
body {
  max-width: 90%;
  margin: 1.5em auto;
  color: #222;
  background-color: #fff;
  font-size: 14px;
  font-family: var(--font-sans);
  line-height: 1.6;
  scroll-behavior: smooth;
  overflow-wrap: break-word;
}
.ears {
  display: none;
}

/* headings */
#title, h1, h2, h3, h4, h5, h6 {
  margin: 1em 0 0.5em;
  font-weight: bold;
  line-height: 1.3;
}
#title {
  clear: both;
  border-bottom: 1px solid #ddd;
  margin: 0 0 0.5em 0;
  padding: 1em 0 0.5em;
}
.author {
  padding-bottom: 4px;
}
h1 {
  font-size: 26px;
  margin: 1em 0;
}
h2 {
  font-size: 22px;
  margin-top: -20px;  /* provide offset for in-page anchors */
  padding-top: 33px;
}
h3 {
  font-size: 18px;
  margin-top: -36px;  /* provide offset for in-page anchors */
  padding-top: 42px;
}
h4 {
  font-size: 16px;
  margin-top: -36px;  /* provide offset for in-page anchors */
  padding-top: 42px;
}
h5, h6 {
  font-size: 14px;
}
#n-copyright-notice {
  border-bottom: 1px solid #ddd;
  padding-bottom: 1em;
  margin-bottom: 1em;
}
/* general structure */
p {
  padding: 0;
  margin: 0 0 1em 0;
  text-align: left;
}
div, span {
  position: relative;
}
div {
  margin: 0;
}
.alignRight.art-text {
  background-color: #f9f9f9;
  border: 1px solid #eee;
  border-radius: 3px;
  padding: 1em 1em 0;
  margin-bottom: 1.5em;
}
.alignRight.art-text pre {
  padding: 0;
}
.alignRight {
  margin: 1em 0;
}
.alignRight > *:first-child {
  border: none;
  margin: 0;
  float: right;
  clear: both;
}
.alignRight > *:nth-child(2) {
  clear: both;
  display: block;
  border: none;
}
svg {
  display: block;
}
svg[font-family~="serif" i], svg [font-family~="serif" i] {
  font-family: var(--font-serif);
}
svg[font-family~="sans-serif" i], svg [font-family~="sans-serif" i] {
  font-family: var(--font-sans);
}
svg[font-family~="monospace" i], svg [font-family~="monospace" i] {
  font-family: var(--font-mono);
}
.alignCenter.art-text {
  background-color: #f9f9f9;
  border: 1px solid #eee;
  border-radius: 3px;
  padding: 1em 1em 0;
  margin-bottom: 1.5em;
}
.alignCenter.art-text pre {
  padding: 0;
}
.alignCenter {
  margin: 1em 0;
}
.alignCenter > *:first-child {
  display: table;
  border: none;
  margin: 0 auto;
}

/* lists */
ol, ul {
  padding: 0;
  margin: 0 0 1em 2em;
}
ol ol, ul ul, ol ul, ul ol {
  margin-left: 1em;
}
li {
  margin: 0 0 0.25em 0;
}
.ulCompact li {
  margin: 0;
}
ul.empty, .ulEmpty {
  list-style-type: none;
}
ul.empty li, .ulEmpty li {
  margin-top: 0.5em;
}
ul.ulBare, li.ulBare {
  margin-left: 0em !important;
}
ul.compact, .ulCompact,
ol.compact, .olCompact {
  line-height: 100%;
  margin: 0 0 0 2em;
}

/* definition lists */
dl {
}
dl > dt {
  float: left;
  margin-right: 1em;
}
/* 
dl.nohang > dt {
  float: none;
}
*/
dl > dd {
  margin-bottom: .8em;
  min-height: 1.3em;
}
dl.compact > dd, .dlCompact > dd {
  margin-bottom: 0em;
}
dl > dd > dl {
  margin-top: 0.5em;
  margin-bottom: 0em;
}

/* links */
a {
  text-decoration: none;
}
a[href] {
  color: #22e; /* Arlen: WCAG 2019 */
}
a[href]:hover {
  background-color: #f2f2f2;
}
figcaption a[href],
a[href].selfRef {
  color: #222;
}
/* XXX probably not this:
a.selfRef:hover {
  background-color: transparent;
  cursor: default;
} */

/* Figures */
tt, code, pre {
  background-color: #f9f9f9;
  font-family: var(--font-mono);
}
pre {
  border: 1px solid #eee;
  margin: 0;
  padding: 1em;
}
img {
  max-width: 100%;
}
figure {
  margin: 0;
}
figure blockquote {
  margin: 0.8em 0.4em 0.4em;
}
figcaption {
  font-style: italic;
  margin: 0 0 1em 0;
}
@media screen {
  pre {
    overflow-x: auto;
    max-width: 100%;
    max-width: calc(100% - 22px);
  }
}

/* aside, blockquote */
aside, blockquote {
  margin-left: 0;
  padding: 1.2em 2em;
}
blockquote {
  background-color: #f9f9f9;
  color: #111; /* Arlen: WCAG 2019 */
  border: 1px solid #ddd;
  border-radius: 3px;
  margin: 1em 0;
}
blockquote > *:last-child {
  margin-bottom: 0;
}
cite {
  display: block;
  text-align: right;
  font-style: italic;
}
.xref {
  overflow-wrap: normal;
}

/* tables */
table {
  width: 100%;
  margin: 0 0 1em;
  border-collapse: collapse;
  border: 1px solid #eee;
}
th, td {
  text-align: left;
  vertical-align: top;
  padding: 0.5em 0.75em;
}
th {
  text-align: left;
  background-color: #e9e9e9;
}
tr:nth-child(2n+1) > td {
  background-color: #f5f5f5;
}
table caption {
  font-style: italic;
  margin: 0;
  padding: 0;
  text-align: left;
}
table p {
  /* XXX to avoid bottom margin on table row signifiers. If paragraphs should
     be allowed within tables more generally, it would be far better to select on a class. */
  margin: 0;
}

/* pilcrow */
a.pilcrow {
  color: #666; /* Arlen: AHDJ 2019 */
  text-decoration: none;
  visibility: hidden;
  user-select: none;
  -ms-user-select: none;
  -o-user-select:none;
  -moz-user-select: none;
  -khtml-user-select: none;
  -webkit-user-select: none;
  -webkit-touch-callout: none;
}
@media screen {
  aside:hover > a.pilcrow,
  p:hover > a.pilcrow,
  blockquote:hover > a.pilcrow,
  div:hover > a.pilcrow,
  li:hover > a.pilcrow,
  pre:hover > a.pilcrow {
    visibility: visible;
  }
  a.pilcrow:hover {
    background-color: transparent;
  }
}

/* misc */
hr {
  border: 0;
  border-top: 1px solid #eee;
}
.bcp14 {
  font-variant: small-caps;
}

.role {
  font-variant: all-small-caps;
}

/* info block */
#identifiers {
  margin: 0;
  font-size: 0.9em;
}
#identifiers dt {
  width: 3em;
  clear: left;
}
#identifiers dd {
  float: left;
  margin-bottom: 0;
}
/* Fix PDF info block run off issue */
@media print {
  #identifiers dd {
    float: none;
  }
}
#identifiers .authors .author {
  display: inline-block;
  margin-right: 1.5em;
}
#identifiers .authors .org {
  font-style: italic;
}

/* The prepared/rendered info at the very bottom of the page */
.docInfo {
  color: #666; /* Arlen: WCAG 2019 */
  font-size: 0.9em;
  font-style: italic;
  margin-top: 2em;
}
.docInfo .prepared {
  float: left;
}
.docInfo .prepared {
  float: right;
}

/* table of contents */
#toc  {
  padding: 0.75em 0 2em 0;
  margin-bottom: 1em;
}
nav.toc ul {
  margin: 0 0.5em 0 0;
  padding: 0;
  list-style: none;
}
nav.toc li {
  line-height: 1.3em;
  margin: 0.75em 0;
  padding-left: 1.2em;
  text-indent: -1.2em;
}
/* references */
.references dt {
  text-align: right;
  font-weight: bold;
  min-width: 7em;
}
.references dd {
  margin-left: 8em;
  overflow: auto;
}

.refInstance {
  margin-bottom: 1.25em;
}

.refSubseries {
  margin-bottom: 1.25em;
}

.references .ascii {
  margin-bottom: 0.25em;
}

/* index */
.index ul {
  margin: 0 0 0 1em;
  padding: 0;
  list-style: none;
}
.index ul ul {
  margin: 0;
}
.index li {
  margin: 0;
  text-indent: -2em;
  padding-left: 2em;
  padding-bottom: 5px;
}
.indexIndex {
  margin: 0.5em 0 1em;
}
.index a {
  font-weight: 700;
}
/* make the index two-column on all but the smallest screens */
@media (min-width: 600px) {
  .index ul {
    -moz-column-count: 2;
    -moz-column-gap: 20px;
  }
  .index ul ul {
    -moz-column-count: 1;
    -moz-column-gap: 0;
  }
}

/* authors */
address.vcard {
  font-style: normal;
  margin: 1em 0;
}

address.vcard .nameRole {
  font-weight: 700;
  margin-left: 0;
}
address.vcard .label {
  font-family: var(--font-sans);
  margin: 0.5em 0;
}
address.vcard .type {
  display: none;
}
.alternative-contact {
  margin: 1.5em 0 1em;
}
hr.addr {
  border-top: 1px dashed;
  margin: 0;
  color: #ddd;
  max-width: calc(100% - 16px);
}

/* temporary notes */
.rfcEditorRemove::before {
  position: absolute;
  top: 0.2em;
  right: 0.2em;
  padding: 0.2em;
  content: "The RFC Editor will remove this note";
  color: #9e2a00; /* Arlen: WCAG 2019 */
  background-color: #ffd; /* Arlen: WCAG 2019 */
}
.rfcEditorRemove {
  position: relative;
  padding-top: 1.8em;
  background-color: #ffd; /* Arlen: WCAG 2019 */
  border-radius: 3px;
}
.cref {
  background-color: #ffd; /* Arlen: WCAG 2019 */
  padding: 2px 4px;
}
.crefSource {
  font-style: italic;
}
/* alternative layout for smaller screens */
@media screen and (max-width: 1023px) {
  body {
    padding-top: 2em;
  }
  #title {
    padding: 1em 0;
  }
  h1 {
    font-size: 24px;
  }
  h2 {
    font-size: 20px;
    margin-top: -18px;  /* provide offset for in-page anchors */
    padding-top: 38px;
  }
  #identifiers dd {
    max-width: 60%;
  }
  #toc {
    position: fixed;
    z-index: 2;
    top: 0;
    right: 0;
    padding: 0;
    margin: 0;
    background-color: inherit;
    border-bottom: 1px solid #ccc;
  }
  #toc h2 {
    margin: -1px 0 0 0;
    padding: 4px 0 4px 6px;
    padding-right: 1em;
    min-width: 190px;
    font-size: 1.1em;
    text-align: right;
    background-color: #444;
    color: white;
    cursor: pointer;
  }
  #toc h2::before { /* css hamburger */
    float: right;
    position: relative;
    width: 1em;
    height: 1px;
    left: -164px;
    margin: 6px 0 0 0;
    background: white none repeat scroll 0 0;
    box-shadow: 0 4px 0 0 white, 0 8px 0 0 white;
    content: "";
  }
  #toc nav {
    display: none;
    padding: 0.5em 1em 1em;
    overflow: auto;
    height: calc(100vh - 48px);
    border-left: 1px solid #ddd;
  }
}

/* alternative layout for wide screens */
@media screen and (min-width: 1024px) {
  body {
    max-width: 724px;
    margin: 42px auto;
    padding-left: 1.5em;
    padding-right: 29em;
  }
  #toc {
    position: fixed;
    top: 42px;
    right: 42px;
    width: 25%;
    margin: 0;
    padding: 0 1em;
    z-index: 1;
  }
  #toc h2 {
    border-top: none;
    border-bottom: 1px solid #ddd;
    font-size: 1em;
    font-weight: normal;
    margin: 0;
    padding: 0.25em 1em 1em 0;
  }
  #toc nav {
    display: block;
    height: calc(90vh - 84px);
    bottom: 0;
    padding: 0.5em 0 0;
    overflow: auto;
  }
  img { /* future proofing */
    max-width: 100%;
    height: auto;
  }
}

/* pagination */
@media print {
  body {
    width: 100%;
  }
  p {
    orphans: 3;
    widows: 3;
  }
  #n-copyright-notice {
    border-bottom: none;
  }
  #toc, #n-introduction {
    page-break-before: always;
  }
  #toc {
    border-top: none;
    padding-top: 0;
  }
  figure, pre {
    page-break-inside: avoid;
  }
  figure {
    overflow: scroll;
  }
  .breakable pre {
    break-inside: auto;
  }
  h1, h2, h3, h4, h5, h6 {
    page-break-after: avoid;
  }
  h2+*, h3+*, h4+*, h5+*, h6+* {
    page-break-before: avoid;
  }
  pre {
    white-space: pre-wrap;
    word-wrap: break-word;
    font-size: 10pt;
  }
  table {
    border: 1px solid #ddd;
  }
  td {
    border-top: 1px solid #ddd;
  }
}

/* This is commented out here, as the string-set: doesn't
   pass W3C validation currently */
/*
.ears thead .left {
  string-set: ears-top-left content();
}

.ears thead .center {
  string-set: ears-top-center content();
}

.ears thead .right {
  string-set: ears-top-right content();
}

.ears tfoot .left {
  string-set: ears-bottom-left content();
}

.ears tfoot .center {
  string-set: ears-bottom-center content();
}

.ears tfoot .right {
  string-set: ears-bottom-right content();
}
*/

@page :first {
  padding-top: 0;
  @top-left {
    content: normal;
    border: none;
  }
  @top-center {
    content: normal;
    border: none;
  }
  @top-right {
    content: normal;
    border: none;
  }
}

@page {
  size: A4;
  margin-bottom: 45mm;
  padding-top: 20px;
  /* The following is commented out here, but set appropriately by in code, as
     the content depends on the document */
  /*
  @top-left {
    content: 'Internet-Draft';
    vertical-align: bottom;
    border-bottom: solid 1px #ccc;
  }
  @top-left {
    content: string(ears-top-left);
    vertical-align: bottom;
    border-bottom: solid 1px #ccc;
  }
  @top-center {
    content: string(ears-top-center);
    vertical-align: bottom;
    border-bottom: solid 1px #ccc;
  }
  @top-right {
    content: string(ears-top-right);
    vertical-align: bottom;
    border-bottom: solid 1px #ccc;
  }
  @bottom-left {
    content: string(ears-bottom-left);
    vertical-align: top;
    border-top: solid 1px #ccc;
  }
  @bottom-center {
    content: string(ears-bottom-center);
    vertical-align: top;
    border-top: solid 1px #ccc;
  }
  @bottom-right {
      content: '[Page ' counter(page) ']';
      vertical-align: top;
      border-top: solid 1px #ccc;
  }
  */

}

/* Changes introduced to fix issues found during implementation */
/* Make sure links are clickable even if overlapped by following H* */
a {
  z-index: 2;
}
/* Separate body from document info even without intervening H1 */
section {
  clear: both;
}


/* Top align author divs, to avoid names without organization dropping level with org names */
.author {
  vertical-align: top;
}

/* Leave room in document info to show Internet-Draft on one line */
#identifiers dt {
  width: 8em;
}

/* Don't waste quite as much whitespace between label and value in doc info */
#identifiers dd {
  margin-left: 1em;
}

/* Give floating toc a background color (needed when it's a div inside section */
#toc {
  background-color: white;
}

/* Make the collapsed ToC header render white on gray also when it's a link */
@media screen and (max-width: 1023px) {
  #toc h2 a,
  #toc h2 a:link,
  #toc h2 a:focus,
  #toc h2 a:hover,
  #toc a.toplink,
  #toc a.toplink:hover {
    color: white;
    background-color: #444;
    text-decoration: none;
  }
}

/* Give the bottom of the ToC some whitespace */
@media screen and (min-width: 1024px) {
  #toc {
    padding: 0 0 1em 1em;
  }
}

/* Style section numbers with more space between number and title */
.section-number {
  padding-right: 0.5em;
}

/* prevent monospace from becoming overly large */
tt, code, pre {
  font-size: 95%;
}

/* Fix the height/width aspect for ascii art*/
.sourcecode pre,
.art-text pre {
  line-height: 1.12;
}


/* Add styling for a link in the ToC that points to the top of the document */
a.toplink {
  float: right;
  margin-right: 0.5em;
}

/* Fix the dl styling to match the RFC 7992 attributes */
dl > dt,
dl.dlParallel > dt {
  float: left;
  margin-right: 1em;
}
dl.dlNewline > dt {
  float: none;
}

/* Provide styling for table cell text alignment */
table td.text-left,
table th.text-left {
  text-align: left;
}
table td.text-center,
table th.text-center {
  text-align: center;
}
table td.text-right,
table th.text-right {
  text-align: right;
}

/* Make the alternative author contact information look less like just another
   author, and group it closer with the primary author contact information */
.alternative-contact {
  margin: 0.5em 0 0.25em 0;
}
address .non-ascii {
  margin: 0 0 0 2em;
}

/* With it being possible to set tables with alignment
  left, center, and right, { width: 100%; } does not make sense */
table {
  width: auto;
}

/* Avoid reference text that sits in a block with very wide left margin,
   because of a long floating dt label.*/
.references dd {
  overflow: visible;
}

/* Control caption placement */
caption {
  caption-side: bottom;
}

/* Limit the width of the author address vcard, so names in right-to-left
   script don't end up on the other side of the page. */

address.vcard {
  max-width: 30em;
  margin-right: auto;
}

/* For address alignment dependent on LTR or RTL scripts */
address div.left {
  text-align: left;
}
address div.right {
  text-align: right;
}

/* Provide table alignment support.  We can't use the alignX classes above
   since they do unwanted things with caption and other styling. */
table.right {
 margin-left: auto;
 margin-right: 0;
}
table.center {
 margin-left: auto;
 margin-right: auto;
}
table.left {
 margin-left: 0;
 margin-right: auto;
}

/* Give the table caption label the same styling as the figcaption */
caption a[href] {
  color: #222;
}

@media print {
  .toplink {
    display: none;
  }

  /* avoid overwriting the top border line with the ToC header */
  #toc {
    padding-top: 1px;
  }

  /* Avoid page breaks inside dl and author address entries */
  .vcard {
    page-break-inside: avoid;
  }

}
/* Tweak the bcp14 keyword presentation */
.bcp14 {
  font-variant: small-caps;
  font-weight: bold;
  font-size: 0.9em;
}
/* Tweak the invisible space above H* in order not to overlay links in text above */
 h2 {
  margin-top: -18px;  /* provide offset for in-page anchors */
  padding-top: 31px;
 }
 h3 {
  margin-top: -18px;  /* provide offset for in-page anchors */
  padding-top: 24px;
 }
 h4 {
  margin-top: -18px;  /* provide offset for in-page anchors */
  padding-top: 24px;
 }
/* Float artwork pilcrow to the right */
@media screen {
  .artwork a.pilcrow {
    display: block;
    line-height: 0.7;
    margin-top: 0.15em;
  }
}
/* Make pilcrows on dd visible */
@media screen {
  dd:hover > a.pilcrow {
    visibility: visible;
  }
}
/* Make the placement of figcaption match that of a table's caption
   by removing the figure's added bottom margin */
.alignLeft.art-text,
.alignCenter.art-text,
.alignRight.art-text {
   margin-bottom: 0;
}
.alignLeft,
.alignCenter,
.alignRight {
  margin: 1em 0 0 0;
}
/* In print, the pilcrow won't show on hover, so prevent it from taking up space,
   possibly even requiring a new line */
@media print {
  a.pilcrow {
    display: none;
  }
}
/* Styling for the external metadata */
div#external-metadata {
  background-color: #eee;
  padding: 0.5em;
  margin-bottom: 0.5em;
  display: none;
}
div#internal-metadata {
  padding: 0.5em;                       /* to match the external-metadata padding */
}
/* Styling for title RFC Number */
h1#rfcnum {
  clear: both;
  margin: 0 0 -1em;
  padding: 1em 0 0 0;
}
/* Make .olPercent look the same as <ol><li> */
dl.olPercent > dd {
  margin-bottom: 0.25em;
  min-height: initial;
}
/* Give aside some styling to set it apart */
aside {
  border-left: 1px solid #ddd;
  margin: 1em 0 1em 2em;
  padding: 0.2em 2em;
}
aside > dl,
aside > ol,
aside > ul,
aside > table,
aside > p {
  margin-bottom: 0.5em;
}
/* Additional page break settings */
@media print {
  figcaption, table caption {
    page-break-before: avoid;
  }
}
/* Font size adjustments for print */
@media print {
  body  { font-size: 10pt;      line-height: normal; max-width: 96%; }
  h1    { font-size: 1.72em;    padding-top: 1.5em; } /* 1*1.2*1.2*1.2 */
  h2    { font-size: 1.44em;    padding-top: 1.5em; } /* 1*1.2*1.2 */
  h3    { font-size: 1.2em;     padding-top: 1.5em; } /* 1*1.2 */
  h4    { font-size: 1em;       padding-top: 1.5em; }
  h5, h6 { font-size: 1em;      margin: initial; padding: 0.5em 0 0.3em; }
}
/* Sourcecode margin in print, when there's no pilcrow */
@media print {
  .artwork,
  .artwork > pre,
  .sourcecode {
    margin-bottom: 1em;
  }
}
/* Avoid narrow tables forcing too narrow table captions, which may render badly */
table {
  min-width: 20em;
}
/* ol type a */
ol.type-a { list-style-type: lower-alpha; }
ol.type-A { list-style-type: upper-alpha; }
ol.type-i { list-style-type: lower-roman; }
ol.type-I { list-style-type: upper-roman; }
/* Apply the print table and row borders in general, on request from the RPC,
and increase the contrast between border and odd row background slightly */
table {
  border: 1px solid #ddd;
}
td {
  border-top: 1px solid #ddd;
}
tr {
  break-inside: avoid;
}
tr:nth-child(2n+1) > td {
  background-color: #f8f8f8;
}
/* Use style rules to govern display of the TOC. */
@media screen and (max-width: 1023px) {
  #toc nav { display: none; }
  #toc.active nav { display: block; }
}
/* Add support for keepWithNext */
.keepWithNext {
  break-after: avoid-page;
  break-after: avoid-page;
}
/* Add support for keepWithPrevious */
.keepWithPrevious {
  break-before: avoid-page;
}
/* Change the approach to avoiding breaks inside artwork etc. */
figure, pre, table, .artwork, .sourcecode  {
  break-before: auto;
  break-after: auto;
}
/* Avoid breaks between <dt> and <dd> */
dl {
  break-before: auto;
  break-inside: auto;
}
dt {
  break-before: auto;
  break-after: avoid-page;
}
dd {
  break-before: avoid-page;
  break-after: auto;
  orphans: 3;
  widows: 3
}
span.break, dd.break {
  margin-bottom: 0;
  min-height: 0;
  break-before: auto;
  break-inside: auto;
  break-after: auto;
}
/* Undo break-before ToC */
@media print {
  #toc {
    break-before: auto;
  }
}
/* Text in compact lists should not get extra bottom margin space,
   since that would makes the list not compact */
ul.compact p, .ulCompact p,
ol.compact p, .olCompact p {
 margin: 0;
}
/* But the list as a whole needs the extra space at the end */
section ul.compact,
section .ulCompact,
section ol.compact,
section .olCompact {
  margin-bottom: 1em;                    /* same as p not within ul.compact etc. */
}
/* The tt and code background above interferes with for instance table cell
   backgrounds.  Changed to something a bit more selective. */
tt, code {
  background-color: transparent;
}
p tt, p code, li tt, li code, dt tt, dt code {
  background-color: #f8f8f8;
}
/* Tweak the pre margin -- 0px doesn't come out well */
pre {
   margin-top: 0.5px;
}
/* Tweak the compact list text */
ul.compact, .ulCompact,
ol.compact, .olCompact,
dl.compact, .dlCompact {
  line-height: normal;
}
/* Don't add top margin for nested lists */
li > ul, li > ol, li > dl,
dd > ul, dd > ol, dd > dl,
dl > dd > dl {
  margin-top: initial;
}
/* Elements that should not be rendered on the same line as a <dt> */
/* This should match the element list in writer.text.TextWriter.render_dl() */
dd > div.artwork:first-child,
dd > aside:first-child,
dd > figure:first-child,
dd > ol:first-child,
dd > div.sourcecode:first-child,
dd > table:first-child,
dd > ul:first-child {
  clear: left;
}
/* fix for weird browser behaviour when <dd/> is empty */
dt+dd:empty::before{
  content: "\00a0";
}
/* Make paragraph spacing inside <li> smaller than in body text, to fit better within the list */
li > p {
  margin-bottom: 0.5em
}
/* Don't let p margin spill out from inside list items */
li > p:last-of-type:only-child {
  margin-bottom: 0;
}
</style>
<link href="rfc-local.css" rel="stylesheet" type="text/css">
<link href="https://datatracker.ietf.org/doc/draft-ietf-mops-ar-use-case-18" rel="prev">
  <link href="https://dx.doi.org/10.17487/rfc9699" rel="alternate">
  <link href="urn:issn:2070-1721" rel="alternate">
  </head>
<body class="xml2rfc">
<script src="https://www.rfc-editor.org/js/metadata.min.js"></script>
<table class="ears">
<thead><tr>
<td class="left">RFC 9699</td>
<td class="center">XR Use Case</td>
<td class="right">December 2024</td>
</tr></thead>
<tfoot><tr>
<td class="left">Krishna &amp; Rahman</td>
<td class="center">Informational</td>
<td class="right">[Page]</td>
</tr></tfoot>
</table>
<div id="external-metadata" class="document-information"></div>
<div id="internal-metadata" class="document-information">
<dl id="identifiers">
<dt class="label-stream">Stream:</dt>
<dd class="stream">Internet Engineering Task Force (IETF)</dd>
<dt class="label-rfc">RFC:</dt>
<dd class="rfc"><a href="https://www.rfc-editor.org/rfc/rfc9699" class="eref">9699</a></dd>
<dt class="label-category">Category:</dt>
<dd class="category">Informational</dd>
<dt class="label-published">Published:</dt>
<dd class="published">
<time datetime="2024-12" class="published">December 2024</time>
    </dd>
<dt class="label-issn">ISSN:</dt>
<dd class="issn">2070-1721</dd>
<dt class="label-authors">Authors:</dt>
<dd class="authors">
<div class="author">
      <div class="author-name">R. Krishna</div>
</div>
<div class="author">
      <div class="author-name">A. Rahman</div>
<div class="org">Ericsson</div>
</div>
</dd>
</dl>
</div>
<h1 id="rfcnum">RFC 9699</h1>
<h1 id="title">Use Case for an Extended Reality Application on Edge Computing Infrastructure</h1>
<section id="section-abstract">
      <h2 id="abstract"><a href="#abstract" class="selfRef">Abstract</a></h2>
<p id="section-abstract-1">This document explores the issues involved in the use of edge
      computing resources to operationalize a media use case that involves an
      Extended Reality (XR) application. In particular, this document
      discusses an XR application that can run on devices having different
      form factors (such as different physical sizes and shapes) and needs edge
      computing resources to mitigate the effect of problems such as the need
      to support interactive communication requiring low latency, limited
      battery power, and heat dissipation from those devices.  This document
      also discusses the expected behavior of XR applications, which can be
      used to manage traffic, and the service requirements for XR applications
      to be able to run on the network. Network operators who are interested
      in providing edge computing resources to operationalize the requirements
      of such applications are the intended audience for this document.<a href="#section-abstract-1" class="pilcrow">¶</a></p>
</section>
<div id="status-of-memo">
<section id="section-boilerplate.1">
        <h2 id="name-status-of-this-memo">
<a href="#name-status-of-this-memo" class="section-name selfRef">Status of This Memo</a>
        </h2>
<p id="section-boilerplate.1-1">
            This document is not an Internet Standards Track specification; it is
            published for informational purposes.<a href="#section-boilerplate.1-1" class="pilcrow">¶</a></p>
<p id="section-boilerplate.1-2">
            This document is a product of the Internet Engineering Task Force
            (IETF).  It represents the consensus of the IETF community.  It has
            received public review and has been approved for publication by the
            Internet Engineering Steering Group (IESG).  Not all documents
            approved by the IESG are candidates for any level of Internet
            Standard; see Section 2 of RFC 7841.<a href="#section-boilerplate.1-2" class="pilcrow">¶</a></p>
<p id="section-boilerplate.1-3">
            Information about the current status of this document, any
            errata, and how to provide feedback on it may be obtained at
            <span><a href="https://www.rfc-editor.org/info/rfc9699">https://www.rfc-editor.org/info/rfc9699</a></span>.<a href="#section-boilerplate.1-3" class="pilcrow">¶</a></p>
</section>
</div>
<div id="copyright">
<section id="section-boilerplate.2">
        <h2 id="name-copyright-notice">
<a href="#name-copyright-notice" class="section-name selfRef">Copyright Notice</a>
        </h2>
<p id="section-boilerplate.2-1">
            Copyright (c) 2024 IETF Trust and the persons identified as the
            document authors. All rights reserved.<a href="#section-boilerplate.2-1" class="pilcrow">¶</a></p>
<p id="section-boilerplate.2-2">
            This document is subject to BCP 78 and the IETF Trust's Legal
            Provisions Relating to IETF Documents
            (<span><a href="https://trustee.ietf.org/license-info">https://trustee.ietf.org/license-info</a></span>) in effect on the date of
            publication of this document. Please review these documents
            carefully, as they describe your rights and restrictions with
            respect to this document. Code Components extracted from this
            document must include Revised BSD License text as described in
            Section 4.e of the Trust Legal Provisions and are provided without
            warranty as described in the Revised BSD License.<a href="#section-boilerplate.2-2" class="pilcrow">¶</a></p>
</section>
</div>
<div id="toc">
<section id="section-toc.1">
        <a href="#" onclick="scroll(0,0)" class="toplink">▲</a><h2 id="name-table-of-contents">
<a href="#name-table-of-contents" class="section-name selfRef">Table of Contents</a>
        </h2>
<nav class="toc"><ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.1">
            <p id="section-toc.1-1.1.1" class="keepWithNext"><a href="#section-1" class="auto internal xref">1</a>.  <a href="#name-introduction" class="internal xref">Introduction</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2">
            <p id="section-toc.1-1.2.1"><a href="#section-2" class="auto internal xref">2</a>.  <a href="#name-use-case" class="internal xref">Use Case</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.1">
                <p id="section-toc.1-1.2.2.1.1" class="keepWithNext"><a href="#section-2.1" class="auto internal xref">2.1</a>.  <a href="#name-processing-of-scenes" class="internal xref">Processing of Scenes</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.2.2.2">
                <p id="section-toc.1-1.2.2.2.1" class="keepWithNext"><a href="#section-2.2" class="auto internal xref">2.2</a>.  <a href="#name-generation-of-images" class="internal xref">Generation of Images</a></p>
</li>
            </ul>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.3">
            <p id="section-toc.1-1.3.1"><a href="#section-3" class="auto internal xref">3</a>.  <a href="#name-technical-challenges-and-so" class="internal xref">Technical Challenges and Solutions</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.4">
            <p id="section-toc.1-1.4.1"><a href="#section-4" class="auto internal xref">4</a>.  <a href="#name-xr-network-traffic" class="internal xref">XR Network Traffic</a></p>
<ul class="compact toc ulBare ulEmpty">
<li class="compact toc ulBare ulEmpty" id="section-toc.1-1.4.2.1">
                <p id="section-toc.1-1.4.2.1.1"><a href="#section-4.1" class="auto internal xref">4.1</a>.  <a href="#name-traffic-workload" class="internal xref">Traffic Workload</a></p>
</li>
              <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.4.2.2">
                <p id="section-toc.1-1.4.2.2.1"><a href="#section-4.2" class="auto internal xref">4.2</a>.  <a href="#name-traffic-performance-metrics" class="internal xref">Traffic Performance Metrics</a></p>
</li>
            </ul>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.5">
            <p id="section-toc.1-1.5.1"><a href="#section-5" class="auto internal xref">5</a>.  <a href="#name-conclusion" class="internal xref">Conclusion</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.6">
            <p id="section-toc.1-1.6.1"><a href="#section-6" class="auto internal xref">6</a>.  <a href="#name-iana-considerations" class="internal xref">IANA Considerations</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.7">
            <p id="section-toc.1-1.7.1"><a href="#section-7" class="auto internal xref">7</a>.  <a href="#name-security-considerations" class="internal xref">Security Considerations</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.8">
            <p id="section-toc.1-1.8.1"><a href="#section-8" class="auto internal xref">8</a>.  <a href="#name-informative-references" class="internal xref">Informative References</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.9">
            <p id="section-toc.1-1.9.1"><a href="#appendix-A" class="auto internal xref"></a><a href="#name-acknowledgements" class="internal xref">Acknowledgements</a></p>
</li>
          <li class="compact toc ulBare ulEmpty" id="section-toc.1-1.10">
            <p id="section-toc.1-1.10.1"><a href="#appendix-B" class="auto internal xref"></a><a href="#name-authors-addresses" class="internal xref">Authors' Addresses</a></p>
</li>
        </ul>
</nav>
</section>
</div>
<div id="introduction">
<section id="section-1">
      <h2 id="name-introduction">
<a href="#section-1" class="section-number selfRef">1. </a><a href="#name-introduction" class="section-name selfRef">Introduction</a>
      </h2>
<p id="section-1-1">
 Extended Reality (XR) is a term that includes Augmented
 Reality (AR), Virtual Reality (VR), and Mixed Reality (MR)
 <span>[<a href="#XR" class="cite xref">XR</a>]</span>.  AR combines the real
 and virtual, is interactive, and is aligned to the physical
 world of the user <span>[<a href="#AUGMENTED_2" class="cite xref">AUGMENTED_2</a>]</span>. On the other hand, VR places the user
 inside a virtual environment generated by a computer <span>[<a href="#AUGMENTED" class="cite xref">AUGMENTED</a>]</span>. MR merges the real and
 virtual along a continuum that connects a completely real
 environment at one end to a completely virtual environment at
 the other end. In this continuum, all combinations of the real
 and virtual are captured <span>[<a href="#AUGMENTED" class="cite xref">AUGMENTED</a>]</span>.<a href="#section-1-1" class="pilcrow">¶</a></p>
<p id="section-1-2">
     XR applications have several requirements for the network and the
     mobile devices running these applications.  Some XR applications
     (such as AR applications) require real-time processing of video
     streams to recognize specific objects. This processing is then
     used to overlay information on the video being displayed to the
     user.  In addition, other XR applications (such as AR and VR applications) also
     require generation of new video frames to be played to the
     user. Both the real-time processing of video streams and the
     generation of overlay information are computationally intensive
     tasks that generate heat <span>[<a href="#DEV_HEAT_1" class="cite xref">DEV_HEAT_1</a>]</span> <span>[<a href="#DEV_HEAT_2" class="cite xref">DEV_HEAT_2</a>]</span>
     and drain battery power <span>[<a href="#BATT_DRAIN" class="cite xref">BATT_DRAIN</a>]</span> on the mobile device running the XR
     application.  Consequently, in order to run applications with XR
     characteristics on mobile devices, computationally intensive tasks
     need to be offloaded to resources provided by edge computing.<a href="#section-1-2" class="pilcrow">¶</a></p>
<p id="section-1-3">
 Edge computing is an emerging paradigm where, for the purpose of this document, computing resources and storage are made available in close
 network proximity at the edge of the Internet to mobile devices and sensors <span>[<a href="#EDGE_1" class="cite xref">EDGE_1</a>]</span> <span>[<a href="#EDGE_2" class="cite xref">EDGE_2</a>]</span>. A computing resource or storage is in
 close network proximity to a mobile device or sensor if there is a short and high-capacity network path to it
 such that the latency and bandwidth requirements of applications running on those mobile devices or sensors can be met.
 These edge computing devices use cloud technologies that enable them to support offloaded XR applications. In particular, cloud implementation techniques <span>[<a href="#EDGE_3" class="cite xref">EDGE_3</a>]</span> such as the following can be deployed:<a href="#section-1-3" class="pilcrow">¶</a></p>
<span class="break"></span><dl class="dlParallel" id="section-1-4">
        <dt id="section-1-4.1">Disaggregation:</dt>
        <dd style="margin-left: 1.5em" id="section-1-4.2">Using Software-Defined Networking (SDN) to break vertically integrated systems into independent components. These components can have open interfaces that are standard, well documented, and non-proprietary.<a href="#section-1-4.2" class="pilcrow">¶</a>
</dd>
        <dd class="break"></dd>
<dt id="section-1-4.3">Virtualization:</dt>
        <dd style="margin-left: 1.5em" id="section-1-4.4">Being able to run multiple independent copies of those components, such as SDN Controller applications and Virtual Network Functions, on a
 common hardware platform.<a href="#section-1-4.4" class="pilcrow">¶</a>
</dd>
        <dd class="break"></dd>
<dt id="section-1-4.5">Commoditization:</dt>
        <dd style="margin-left: 1.5em" id="section-1-4.6">Being able to elastically scale those virtual components across commodity hardware as the workload dictates.<a href="#section-1-4.6" class="pilcrow">¶</a>
</dd>
      <dd class="break"></dd>
</dl>
<p id="section-1-5">
  Such techniques enable XR applications that require low latency and high bandwidth to be delivered by proximate edge devices. This is because the disaggregated components can run on proximate edge devices rather than on a remote cloud several hops away and deliver low-latency, high-bandwidth service to offloaded applications <span>[<a href="#EDGE_2" class="cite xref">EDGE_2</a>]</span>.<a href="#section-1-5" class="pilcrow">¶</a></p>
<p id="section-1-6">
   This document discusses the issues involved when edge computing
   resources are offered by network operators to operationalize the
   requirements of XR applications running on devices with various form
   factors. For the purpose of this document, a network operator is any
   organization or individual that manages or operates the computing
   resources or storage in close network proximity to a mobile device
   or sensor.  Examples of form factors include the following: 1)
   head-mounted displays (HMDs), such as optical see-through HMDs and
   video see-through HMDs, 2) hand-held displays, and 3) smartphones
   with video cameras and location-sensing capabilities using systems
   such as a global navigation satellite system (GNSS).  These devices
   have limited battery capacity and dissipate heat when running. Also,
   as the user of these devices moves around as they run the XR
   application, the wireless latency and bandwidth available to the
   devices fluctuates, and the communication link itself might fail. As
   a result, algorithms such as those based on Adaptive Bitrate (ABR)
   techniques that base their policy on heuristics or models of
   deployment perform sub-optimally in such dynamic environments <span>[<a href="#ABR_1" class="cite xref">ABR_1</a>]</span>.  In addition, network operators
   can expect that the parameters that characterize the expected
   behavior of XR applications are heavy-tailed. Heaviness of tails is
   defined as the difference from the normal distribution in the
   proportion of the values that fall a long way from the mean <span>[<a href="#HEAVY_TAIL_3" class="cite xref">HEAVY_TAIL_3</a>]</span>. Such workloads require
   appropriate resource management policies to be used on the edge.
   The service requirements of XR applications are also challenging
   when compared to current video applications.  In particular, several
   Quality-of-Experience (QoE) factors such as motion sickness are
   unique to XR applications and must be considered when
   operationalizing a network.


 This document examines these issues with the use case presented in the following section.<a href="#section-1-6" class="pilcrow">¶</a></p>
</section>
</div>
<div id="use_case">
<section id="section-2">
      <h2 id="name-use-case">
<a href="#section-2" class="section-number selfRef">2. </a><a href="#name-use-case" class="section-name selfRef">Use Case</a>
      </h2>
<p id="section-2-1">
This use case involves an XR application running on a mobile device. Consider
a group of tourists who are taking a tour around the historical site of the
Tower of London.  As they move around the site and within the historical
buildings, they can watch and listen to historical scenes in 3D that are
generated by the XR application and then overlaid by their XR headsets onto
their real-world view. The headset continuously updates their view as they
move around.<a href="#section-2-1" class="pilcrow">¶</a></p>
<p id="section-2-2">
 The XR  application first processes the scene that the walking tourist is watching in real time and identifies objects
 that will be targeted for overlay of high-resolution videos. It then generates high-resolution 3D images
 of historical scenes related to the perspective of the tourist in real time. These generated video images are then
 overlaid on the view of the real world as seen by the tourist.<a href="#section-2-2" class="pilcrow">¶</a></p>
<p id="section-2-3">
 This  processing of scenes
 and generation of high-resolution images are discussed in greater detail below.<a href="#section-2-3" class="pilcrow">¶</a></p>
<div id="processsing_of_scenes">
<section id="section-2.1">
        <h3 id="name-processing-of-scenes">
<a href="#section-2.1" class="section-number selfRef">2.1. </a><a href="#name-processing-of-scenes" class="section-name selfRef">Processing of Scenes</a>
        </h3>
<p id="section-2.1-1">
 The task of processing a scene can be broken down into a pipeline of three consecutive subtasks: tracking, acquisition of a
 model of the real world, and registration <span>[<a href="#AUGMENTED" class="cite xref">AUGMENTED</a>]</span>.<a href="#section-2.1-1" class="pilcrow">¶</a></p>
<span class="break"></span><dl class="dlParallel" id="section-2.1-2">
          <dt id="section-2.1-2.1">Tracking:</dt>
          <dd style="margin-left: 1.5em" id="section-2.1-2.2">The XR application that runs on the mobile device
 needs to track the six-dimensional pose (translational in the
 three perpendicular axes and rotational about those three
 axes) of the user's head, eyes, and objects that are in
 view <span>[<a href="#AUGMENTED" class="cite xref">AUGMENTED</a>]</span>. This
 requires tracking natural features (for example, points or
 edges of objects) that are then used in the next stage of the
 pipeline.<a href="#section-2.1-2.2" class="pilcrow">¶</a>
</dd>
          <dd class="break"></dd>
<dt id="section-2.1-2.3">Acquisition of a model of the real world:</dt>
          <dd style="margin-left: 1.5em" id="section-2.1-2.4">The
 tracked natural features are used to develop a model of the
 real world. One of the ways this is done is to develop a model based on an
 annotated point cloud (a set of points in space that are
 annotated with descriptors) that is then stored in
 a database. To ensure that this database can be scaled up,
 techniques such as combining client-side simultaneous
 tracking and mapping with server-side localization are used
 to construct a model of the real world <span>[<a href="#SLAM_1" class="cite xref">SLAM_1</a>]</span> <span>[<a href="#SLAM_2" class="cite xref">SLAM_2</a>]</span>
            <span>[<a href="#SLAM_3" class="cite xref">SLAM_3</a>]</span> <span>[<a href="#SLAM_4" class="cite xref">SLAM_4</a>]</span>. Another model that can be built is based
 on a polygon mesh and texture mapping technique. The polygon
 mesh encodes a 3D object's shape, which is expressed as a
 collection of small flat surfaces that are polygons. In
 texture mapping, color patterns are mapped onto an object's
 surface. A third modeling technique uses a 2D lightfield that
 describes the intensity or color of the light rays arriving at
 a single point from arbitrary directions. Such a 2D lightfield
 is stored as a two-dimensional table. Assuming distant light
 sources, the single point is approximately valid for small
 scenes. For larger scenes, many 3D positions are additionally
 stored, making the table 5D. A set of all such points (either a
 2D or 5D lightfield) can then be used to construct a model of
 the real world <span>[<a href="#AUGMENTED" class="cite xref">AUGMENTED</a>]</span>.<a href="#section-2.1-2.4" class="pilcrow">¶</a>
</dd>
          <dd class="break"></dd>
<dt id="section-2.1-2.5">Registration:</dt>
          <dd style="margin-left: 1.5em" id="section-2.1-2.6">The coordinate systems,
 brightness, and color of virtual and real objects need to be
 aligned with each other; this process is called
 "registration" <span>[<a href="#REG" class="cite xref">REG</a>]</span>.  Once the
 natural features are tracked as discussed above, virtual
 objects are geometrically aligned with those features by
 geometric registration. This is followed by resolving
 occlusion that can occur between virtual and real objects
 <span>[<a href="#OCCL_1" class="cite xref">OCCL_1</a>]</span> <span>[<a href="#OCCL_2" class="cite xref">OCCL_2</a>]</span>.
 
 The XR application also applies photometric registration <span>[<a href="#PHOTO_REG" class="cite xref">PHOTO_REG</a>]</span> by aligning
 brightness and color between the virtual and real
 objects. Additionally, algorithms that calculate global
 illumination of both the virtual and real objects <span>[<a href="#GLB_ILLUM_1" class="cite xref">GLB_ILLUM_1</a>]</span> <span>[<a href="#GLB_ILLUM_2" class="cite xref">GLB_ILLUM_2</a>]</span> are executed. Various
 algorithms are also required to deal with artifacts generated by lens distortion
 <span>[<a href="#LENS_DIST" class="cite xref">LENS_DIST</a>]</span>, blur <span>[<a href="#BLUR" class="cite xref">BLUR</a>]</span>, noise <span>[<a href="#NOISE" class="cite xref">NOISE</a>]</span>, etc.<a href="#section-2.1-2.6" class="pilcrow">¶</a>
</dd>
        <dd class="break"></dd>
</dl>
</section>
</div>
<div id="generation">
<section id="section-2.2">
        <h3 id="name-generation-of-images">
<a href="#section-2.2" class="section-number selfRef">2.2. </a><a href="#name-generation-of-images" class="section-name selfRef">Generation of Images</a>
        </h3>
<p id="section-2.2-1">
   The XR application must generate a high-quality video that has the
   properties described above and overlay the video on the XR device's
   display.  This step is called "situated visualization". A situated
   visualization is a visualization in which the virtual objects that need to
   be seen by the XR user are overlaid correctly on the real world. This
   entails dealing with registration errors that may arise, ensuring that
   there is no visual interference <span>[<a href="#VIS_INTERFERE" class="cite xref">VIS_INTERFERE</a>]</span>, and finally maintaining temporal coherence by adapting
   to the movement of user's eyes and head.<a href="#section-2.2-1" class="pilcrow">¶</a></p>
</section>
</div>
</section>
</div>
<div id="Req">
<section id="section-3">
      <h2 id="name-technical-challenges-and-so">
<a href="#section-3" class="section-number selfRef">3. </a><a href="#name-technical-challenges-and-so" class="section-name selfRef">Technical Challenges and Solutions</a>
      </h2>
<p id="section-3-1">
 As discussed in <a href="#use_case" class="auto internal xref">Section 2</a>, the components of XR
 applications perform tasks that are computationally intensive, such as
 real-time generation and processing of high-quality video content.
 This section discusses the challenges such applications can face as a
 consequence and offers some solutions.<a href="#section-3-1" class="pilcrow">¶</a></p>
<p id="section-3-2">As a result of performing computationally intensive tasks on XR devices such as XR glasses,
 excessive heat is generated by the chipsets that are involved
 in the computation <span>[<a href="#DEV_HEAT_1" class="cite xref">DEV_HEAT_1</a>]</span> <span>[<a href="#DEV_HEAT_2" class="cite xref">DEV_HEAT_2</a>]</span>.  Additionally,
 the battery on such devices discharges quickly when running
 such applications <span>[<a href="#BATT_DRAIN" class="cite xref">BATT_DRAIN</a>]</span>.<a href="#section-3-2" class="pilcrow">¶</a></p>
<p id="section-3-3">
 A solution to problem of heat dissipation and battery drainage is to offload the processing and video generation tasks
 to the remote cloud. However, running such tasks on the cloud is not feasible as the end-to-end delays
 must be within the order of a few milliseconds. Additionally, such applications require high bandwidth
 and low jitter to provide a high QoE to the user. In order to achieve such hard timing constraints, computationally intensive
 tasks can be offloaded to edge devices.<a href="#section-3-3" class="pilcrow">¶</a></p>
<p id="section-3-4">
 Another requirement for our use case and similar applications, such as 360-degree streaming (streaming of video that represents a view in every direction in 3D space), is that the display on
 the XR device should synchronize the visual input with the way the user is moving their head. This synchronization
 is necessary to avoid motion sickness that results from a time lag between when the user moves their head and
 when the appropriate video scene is rendered. This time lag is often called "motion-to-photon delay".
Studies have shown that this delay
can be at most 20 ms and preferably between 7-15 ms in
order to avoid motion sickness <span>[<a href="#PER_SENSE" class="cite xref">PER_SENSE</a>]</span> <span>[<a href="#XR" class="cite xref">XR</a>]</span> <span>[<a href="#OCCL_3" class="cite xref">OCCL_3</a>]</span>. Out of these 20 ms, display techniques including the refresh
rate of write displays and pixel switching take 12-13 ms <span>[<a href="#OCCL_3" class="cite xref">OCCL_3</a>]</span> <span>[<a href="#CLOUD" class="cite xref">CLOUD</a>]</span>. This leaves 7-8 ms for the processing of
motion sensor inputs, graphic rendering, and round-trip time (RTT) between the XR device and the edge.
The use of predictive techniques to mask latencies has been considered as a mitigating strategy to reduce motion sickness <span>[<a href="#PREDICT" class="cite xref">PREDICT</a>]</span>.
In addition, edge devices that are proximate to the user might be used to offload these computationally intensive tasks.
   Towards this end, a 3GPP study suggests an Ultra-Reliable Low Latency of
   0.1 to 1 ms for communication between an edge server and User Equipment
   (UE) <span>[<a href="#URLLC" class="cite xref">URLLC</a>]</span>.<a href="#section-3-4" class="pilcrow">¶</a></p>
<p id="section-3-5">
 Note that the edge device providing the computation and storage is itself limited in such resources compared to the cloud.  
 For example, a sudden surge in demand from a large group of tourists can overwhelm the device. This will result in a degraded user
  experience as their XR device experiences delays in receiving the video frames. In order to deal
  with this problem, the client XR applications will need to use ABR algorithms that choose bitrate policies
  tailored in a fine-grained manner
  to the resource demands and play back the videos with appropriate QoE metrics as the user moves around with the group of tourists.<a href="#section-3-5" class="pilcrow">¶</a></p>
<p id="section-3-6">
   However, the heavy-tailed nature of several operational parameters (e.g.,
   buffer occupancy, throughput, client-server latency, and variable
   transmission times) makes prediction-based adaptation by ABR algorithms
   sub-optimal <span>[<a href="#ABR_2" class="cite xref">ABR_2</a>]</span>.  This is because with
   such distributions, the law of large numbers (how long it takes for the
   sample mean to stabilize) works too slowly <span>[<a href="#HEAVY_TAIL_2" class="cite xref">HEAVY_TAIL_2</a>]</span> and the mean of sample does not equal the mean of
   distribution <span>[<a href="#HEAVY_TAIL_2" class="cite xref">HEAVY_TAIL_2</a>]</span>; as a result,
   standard deviation and variance are unsuitable as metrics for such
   operational parameters <span>[<a href="#HEAVY_TAIL_1" class="cite xref">HEAVY_TAIL_1</a>]</span>.
   Other subtle issues with these distributions include
   the "expectation paradox" <span>[<a href="#HEAVY_TAIL_1" class="cite xref">HEAVY_TAIL_1</a>]</span>
   (the longer the wait for an event, the longer a further need to wait) and
   the mismatch between the size and count of events <span>[<a href="#HEAVY_TAIL_1" class="cite xref">HEAVY_TAIL_1</a>]</span>. These issues make designing an algorithm
   for adaptation error-prone and challenging.
   In addition, edge devices and
   communication links may fail, and logical communication relationships
   between various software components change frequently as the user moves
   around with their XR device <span>[<a href="#UBICOMP" class="cite xref">UBICOMP</a>]</span>.<a href="#section-3-6" class="pilcrow">¶</a></p>
</section>
</div>
<div id="ArTraffic">
<section id="section-4">
      <h2 id="name-xr-network-traffic">
<a href="#section-4" class="section-number selfRef">4. </a><a href="#name-xr-network-traffic" class="section-name selfRef">XR Network Traffic</a>
      </h2>
<div id="traffic_workload">
<section id="section-4.1">
        <h3 id="name-traffic-workload">
<a href="#section-4.1" class="section-number selfRef">4.1. </a><a href="#name-traffic-workload" class="section-name selfRef">Traffic Workload</a>
        </h3>
<p id="section-4.1-1">
 As discussed in Sections <a href="#introduction" class="auto internal xref">1</a> and <a href="#Req" class="auto internal xref">3</a>, the parameters that capture the characteristics of XR application behavior are heavy-tailed.
 Examples of such parameters include the distribution of arrival times between XR application invocations, the amount
 of data transferred, and the inter-arrival times of packets within a session. As a result, any traffic model based on
 such parameters is also heavy-tailed. Using
 these models to predict performance under alternative resource allocations by the network operator is challenging. For example, both uplink and downlink traffic to a user device has parameters such as volume of XR data, burst time, and idle time that are heavy-tailed.<a href="#section-4.1-1" class="pilcrow">¶</a></p>
<p id="section-4.1-2">


         <a href="#TABLE_1" class="auto internal xref">Table 1</a> below shows various
         streaming video applications and their associated throughput
         requirements <span>[<a href="#METRICS_1" class="cite xref">METRICS_1</a>]</span>. Since our
         use case envisages a 6 degrees of freedom (6DoF) video or point
         cloud, the table indicates that it will require 200 to 1000 Mbps of
         bandwidth.  Also, the table shows that XR applications, such as the
         one in our use case, transmit a larger amount of data per unit time
         as compared to regular video applications. As a result, issues
         arising from heavy-tailed parameters, such as long-range dependent
         traffic <span>[<a href="#METRICS_2" class="cite xref">METRICS_2</a>]</span> and self-similar
         traffic <span>[<a href="#METRICS_3" class="cite xref">METRICS_3</a>]</span>, would be
         experienced at timescales of milliseconds and microseconds rather
         than hours or seconds. Additionally, burstiness at the timescale of
         tens of milliseconds due to the multi-fractal spectrum of traffic
         will be experienced <span>[<a href="#METRICS_4" class="cite xref">METRICS_4</a>]</span>.
         Long-range dependent traffic can have long bursts, and various
         traffic parameters from widely separated times can show correlation
         <span>[<a href="#HEAVY_TAIL_1" class="cite xref">HEAVY_TAIL_1</a>]</span>. Self-similar traffic
         contains bursts at a wide range of timescales <span>[<a href="#HEAVY_TAIL_1" class="cite xref">HEAVY_TAIL_1</a>]</span>. Multi-fractal spectrum
         bursts for traffic summarize the statistical distribution of local
         scaling exponents found in a traffic trace <span>[<a href="#HEAVY_TAIL_1" class="cite xref">HEAVY_TAIL_1</a>]</span>.  The operational
         consequence of XR traffic having characteristics such as long-range
         dependency and self-similarity is that the edge servers to which
         multiple XR devices are connected wirelessly could face long bursts
         of traffic <span>[<a href="#METRICS_2" class="cite xref">METRICS_2</a>]</span> <span>[<a href="#METRICS_3" class="cite xref">METRICS_3</a>]</span>. In addition, multi-fractal
         spectrum burstiness at the scale of milliseconds could induce jitter
         contributing to motion sickness <span>[<a href="#METRICS_4" class="cite xref">METRICS_4</a>]</span>. This is because bursty traffic combined with
         variable queueing delays leads to large delay jitter <span>[<a href="#METRICS_4" class="cite xref">METRICS_4</a>]</span>.  The operators of edge servers
         will need to run a "managed edge cloud service" <span>[<a href="#METRICS_5" class="cite xref">METRICS_5</a>]</span> to deal with the above
         problems. Functionalities that such a managed edge cloud service
         could operationally provide include dynamic placement of XR servers,
         mobility support, and energy management <span>[<a href="#METRICS_6" class="cite xref">METRICS_6</a>]</span>.  Providing support for edge servers in techniques
         such as those described in <span>[<a href="#RFC8939" class="cite xref">RFC8939</a>]</span>,
         <span>[<a href="#RFC9023" class="cite xref">RFC9023</a>]</span>, and <span>[<a href="#RFC9450" class="cite xref">RFC9450</a>]</span> could guarantee performance of XR
         applications. For example, these techniques could be used for the
         link between the XR device and the edge as well as within the managed
         edge cloud service. Another option for network operators could be to
         deploy equipment that supports differentiated services <span>[<a href="#RFC2475" class="cite xref">RFC2475</a>]</span> or per-connection
         Quality-of-Service (QoS) guarantees using RSVP <span>[<a href="#RFC2210" class="cite xref">RFC2210</a>]</span>.<a href="#section-4.1-2" class="pilcrow">¶</a></p>
<p id="section-4.1-3">
     Thus, the provisioning of edge servers (in terms of the number of
     servers, the topology, the placement of servers, the assignment of link
     capacity, CPUs, and Graphics Processing Units (GPUs)) should be performed
     with the above factors in mind.<a href="#section-4.1-3" class="pilcrow">¶</a></p>
<span id="name-throughput-requirements-for"></span><div id="TABLE_1">
<table class="center" id="table-1">
          <caption>
<a href="#table-1" class="selfRef">Table 1</a>:
<a href="#name-throughput-requirements-for" class="selfRef">Throughput Requirements for Streaming Video Applications</a>
          </caption>
<thead>
            <tr>
              <th class="text-left" rowspan="1" colspan="1">Application</th>
              <th class="text-left" rowspan="1" colspan="1">Throughput Required</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.1.1.1">Real-world objects annotated with text and images for workflow assistance (e.g., repair)<a href="#section-4.1-4.2.1.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.1.2.1">1 Mbps<a href="#section-4.1-4.2.1.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.2.1.1">Video conferencing<a href="#section-4.1-4.2.2.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.2.2.1">2 Mbps<a href="#section-4.1-4.2.2.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.3.1.1">3D model and data visualization<a href="#section-4.1-4.2.3.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.3.2.1">2 to 20 Mbps<a href="#section-4.1-4.2.3.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.4.1.1">Two-way 3D telepresence<a href="#section-4.1-4.2.4.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.4.2.1">5 to 25 Mbps<a href="#section-4.1-4.2.4.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.5.1.1">Current-Gen 360-degree video (4K)<a href="#section-4.1-4.2.5.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.5.2.1">10 to 50 Mbps<a href="#section-4.1-4.2.5.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.6.1.1">Next-Gen 360-degree video (8K, 90+ frames per second, high dynamic range, stereoscopic)<a href="#section-4.1-4.2.6.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.6.2.1">50 to 200 Mbps<a href="#section-4.1-4.2.6.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.7.1.1">6DoF video or point cloud<a href="#section-4.1-4.2.7.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.1-4.2.7.2.1">200 to 1000 Mbps<a href="#section-4.1-4.2.7.2.1" class="pilcrow">¶</a></p>
</td>
            </tr>
          </tbody>
        </table>
</div>
</section>
</div>
<div id="traffic_performance">
<section id="section-4.2">
        <h3 id="name-traffic-performance-metrics">
<a href="#section-4.2" class="section-number selfRef">4.2. </a><a href="#name-traffic-performance-metrics" class="section-name selfRef">Traffic Performance Metrics</a>
        </h3>
<p id="section-4.2-1">
   The performance requirements for XR traffic have characteristics that need to be considered when operationalizing a network.
   These characteristics are discussed in this section.<a href="#section-4.2-1" class="pilcrow">¶</a></p>
<p id="section-4.2-2">The bandwidth requirements of XR applications are substantially higher than those of video-based applications.<a href="#section-4.2-2" class="pilcrow">¶</a></p>
<p id="section-4.2-3">The latency requirements of XR applications have been studied recently  <span>[<a href="#XR_TRAFFIC" class="cite xref">XR_TRAFFIC</a>]</span>. The following characteristics were identified:<a href="#section-4.2-3" class="pilcrow">¶</a></p>
<ul class="normal">
<li class="normal" id="section-4.2-4.1">The uploading of data from an XR device to a remote server for processing dominates the end-to-end latency.<a href="#section-4.2-4.1" class="pilcrow">¶</a>
</li>
          <li class="normal" id="section-4.2-4.2"> A lack of visual features in the grid environment can cause increased latencies as the XR device
    uploads additional visual data for processing to the remote server.<a href="#section-4.2-4.2" class="pilcrow">¶</a>
</li>
          <li class="normal" id="section-4.2-4.3">XR applications tend to have large bursts that are separated by significant time gaps.<a href="#section-4.2-4.3" class="pilcrow">¶</a>
</li>
        </ul>
<p id="section-4.2-5"> Additionally, XR applications interact with each other on a timescale of an RTT propagation, and this must be considered when operationalizing a network.<a href="#section-4.2-5" class="pilcrow">¶</a></p>
<p id="section-4.2-6">
            <a href="#TABLE_2" class="auto internal xref">Table 2</a> shows a taxonomy of
            applications with their associated required response times and
            bandwidths (this data is from Table V in <span>[<a href="#METRICS_6" class="cite xref">METRICS_6</a>]</span>). Response times can be defined as the time
            interval between the end of a request submission and the end of
            the corresponding response from a system. If the XR device
            offloads a task to an edge server, the response time of the server
            is the RTT from when a data packet is sent from the XR device
            until a response is received. Note that the required response time
            provides an upper bound for the sum of the time taken by
            computational tasks (such as processing of scenes and generation
            of images) and the RTT. This response time depends only on the QoS
            required by an application. The response time is therefore
            independent of the underlying technology of the network and the
            time taken by the computational tasks.<a href="#section-4.2-6" class="pilcrow">¶</a></p>
<p id="section-4.2-7">
   Our use case requires a response time of 20 ms at most and
   preferably between 7-15 ms, as discussed earlier. This requirement
   for response time is similar to the first two entries in <a href="#TABLE_2" class="auto internal xref">Table 2</a>. Additionally, the required
   bandwidth for our use case is 200 to 1000 Mbps (see <a href="#traffic_workload" class="auto internal xref">Section 4.1</a>).  Since our use case envisages multiple
   users running the XR application on their devices and connecting to
   the edge server that is closest to them, these latency and bandwidth
   connections will grow linearly with the number of users. 
   The operators should match the network provisioning to the maximum
   number of tourists that can be supported by a link to an edge
   server.<a href="#section-4.2-7" class="pilcrow">¶</a></p>
<span id="name-traffic-performance-metrics-"></span><div id="TABLE_2">
<table class="center" id="table-2">
          <caption>
<a href="#table-2" class="selfRef">Table 2</a>:
<a href="#name-traffic-performance-metrics-" class="selfRef">Traffic Performance Metrics of Selected XR Applications</a>
          </caption>
<thead>
            <tr>
              <th class="text-left" rowspan="1" colspan="1"> Application</th>
              <th class="text-left" rowspan="1" colspan="1"> Required Response Time</th>
              <th class="text-left" rowspan="1" colspan="1"> Expected Data Capacity</th>
              <th class="text-left" rowspan="1" colspan="1"> Possible Implementations/ Examples</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.1.1.1">Mobile XR-based remote assistance with uncompressed
   4K (1920x1080 pixels) 120 fps HDR 10-bit real-time video
   stream<a href="#section-4.2-8.2.1.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.1.2.1">Less than 10 milliseconds<a href="#section-4.2-8.2.1.2.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.1.3.1">Greater than 7.5 Gbps<a href="#section-4.2-8.2.1.3.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.1.4.1">Assisting maintenance technicians, Industry 4.0
   remote maintenance, remote assistance in robotics
   industry<a href="#section-4.2-8.2.1.4.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.2.1.1">Indoor and localized outdoor navigation<a href="#section-4.2-8.2.2.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.2.2.1">Less than 20 milliseconds<a href="#section-4.2-8.2.2.2.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.2.3.1">50 to 200 Mbps<a href="#section-4.2-8.2.2.3.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.2.4.1">Guidance in theme parks, shopping malls, archaeological sites, and
   museums<a href="#section-4.2-8.2.2.4.1" class="pilcrow">¶</a></p>
</td>
            </tr>
            <tr>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.3.1.1">Cloud-based mobile XR applications<a href="#section-4.2-8.2.3.1.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.3.2.1">Less than 50 milliseconds<a href="#section-4.2-8.2.3.2.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.3.3.1">50 to 100 Mbps<a href="#section-4.2-8.2.3.3.1" class="pilcrow">¶</a></p>
</td>
              <td class="text-left" rowspan="1" colspan="1">
                <p id="section-4.2-8.2.3.4.1">Google Live View, XR-enhanced Google Translate<a href="#section-4.2-8.2.3.4.1" class="pilcrow">¶</a></p>
</td>
            </tr>
          </tbody>
        </table>
</div>
</section>
</div>
</section>
</div>
<div id="conclusion">
<section id="section-5">
      <h2 id="name-conclusion">
<a href="#section-5" class="section-number selfRef">5. </a><a href="#name-conclusion" class="section-name selfRef">Conclusion</a>
      </h2>
<p id="section-5-1">
     In order to operationalize a use case such as the one presented in this document, a network operator could dimension their network to provide a short and high-capacity network path from the edge computing
     resources or storage to the mobile devices running the XR application. This is required to ensure a response time of 20 ms at most and preferably between 7-15 ms. Additionally, a bandwidth of 200
     to 1000 Mbps is required by such applications. To deal with the characteristics of XR traffic as discussed in this document, network operators could deploy a managed edge cloud service that operationally
     provides dynamic placement of XR servers, mobility support, and energy management. Although the use case is technically feasible, economic viability is an important factor that must be considered.<a href="#section-5-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="iana">
<section id="section-6">
      <h2 id="name-iana-considerations">
<a href="#section-6" class="section-number selfRef">6. </a><a href="#name-iana-considerations" class="section-name selfRef">IANA Considerations</a>
      </h2>
<p id="section-6-1">
     This document has no IANA actions.<a href="#section-6-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="Sec">
<section id="section-7">
      <h2 id="name-security-considerations">
<a href="#section-7" class="section-number selfRef">7. </a><a href="#name-security-considerations" class="section-name selfRef">Security Considerations</a>
      </h2>
<p id="section-7-1">
     The security issues for the presented use case are similar to
     those described in <span>[<a href="#DIST" class="cite xref">DIST</a>]</span>, <span>[<a href="#NIST1" class="cite xref">NIST1</a>]</span>, <span>[<a href="#CWE" class="cite xref">CWE</a>]</span>, and <span>[<a href="#NIST2" class="cite xref">NIST2</a>]</span>. This document does not introduce any new
     security issues.<a href="#section-7-1" class="pilcrow">¶</a></p>
</section>
</div>
<section id="section-8">
      <h2 id="name-informative-references">
<a href="#section-8" class="section-number selfRef">8. </a><a href="#name-informative-references" class="section-name selfRef">Informative References</a>
      </h2>
<dl class="references">
<dt id="ABR_1">[ABR_1]</dt>
      <dd>
<span class="refAuthor">Mao, H.</span>, <span class="refAuthor">Netravali, R.</span>, and <span class="refAuthor">M. Alizadeh</span>, <span class="refTitle">"Neural Adaptive Video Streaming with Pensieve"</span>, <span class="refContent">SIGCOMM '17: Proceedings of the Conference of the ACM Special Interest Group on Data Communication, pp. 197-210</span>, <span class="seriesInfo">DOI 10.1145/3098822.3098843</span>, <time datetime="2017" class="refDate">2017</time>, <span>&lt;<a href="https://dl.acm.org/doi/10.1145/3098822.3098843">https://dl.acm.org/doi/10.1145/3098822.3098843</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="ABR_2">[ABR_2]</dt>
      <dd>
<span class="refAuthor">Yan, F.</span>, <span class="refAuthor">Ayers, H.</span>, <span class="refAuthor">Zhu, C.</span>, <span class="refAuthor">Fouladi, S.</span>, <span class="refAuthor">Hong, J.</span>, <span class="refAuthor">Zhang, K.</span>, <span class="refAuthor">Levis, P.</span>, and <span class="refAuthor">K. Winstein</span>, <span class="refTitle">"Learning in situ: a randomized experiment in video streaming"</span>, <span class="refContent">17th USENIX Symposium on Networked Systems Design and Implementation (NSDI '20), pp. 495-511</span>, <time datetime="2020-02" class="refDate">February 2020</time>, <span>&lt;<a href="https://www.usenix.org/conference/nsdi20/presentation/yan">https://www.usenix.org/conference/nsdi20/presentation/yan</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="AUGMENTED">[AUGMENTED]</dt>
      <dd>
<span class="refAuthor">Schmalstieg, D.</span> and <span class="refAuthor">T. Höllerer</span>, <span class="refTitle">"Augmented Reality: Principles and Practice"</span>, <span class="refContent">Addison-Wesley Professional</span>, <time datetime="2016" class="refDate">2016</time>, <span>&lt;<a href="https://www.oreilly.com/library/view/augmented-reality-principles/9780133153217/">https://www.oreilly.com/library/view/augmented-reality-principles/9780133153217/</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="AUGMENTED_2">[AUGMENTED_2]</dt>
      <dd>
<span class="refAuthor">Azuma, R.T.</span>, <span class="refTitle">"A Survey of Augmented Reality"</span>, <span class="refContent">Presence: Teleoperators and Virtual Environments, vol. 6, no. 4, pp. 355-385</span>, <span class="seriesInfo">DOI 10.1162/pres.1997.6.4.355</span>, <time datetime="1997-08" class="refDate">August 1997</time>, <span>&lt;<a href="https://direct.mit.edu/pvar/article-abstract/6/4/355/18336/A-Survey-of-Augmented-Reality?redirectedFrom=fulltext">https://direct.mit.edu/pvar/article-abstract/6/4/355/18336/A-Survey-of-Augmented-Reality?redirectedFrom=fulltext</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="BATT_DRAIN">[BATT_DRAIN]</dt>
      <dd>
<span class="refAuthor">Seneviratne, S.</span>, <span class="refAuthor">Hu, Y.</span>, <span class="refAuthor">Nguyen, T.</span>, <span class="refAuthor">Lan, G.</span>, <span class="refAuthor">Khalifa, S.</span>, <span class="refAuthor">Thilakarathna, K.</span>, <span class="refAuthor">Hassan, M.</span>, and <span class="refAuthor">A. Seneviratne</span>, <span class="refTitle">"A Survey of Wearable Devices and Challenges"</span>, <span class="refContent">IEEE Communication Surveys and Tutorials, vol. 19 no. 4, pp. 2573-2620</span>, <span class="seriesInfo">DOI 10.1109/COMST.2017.2731979</span>, <time datetime="2017" class="refDate">2017</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/7993011">https://ieeexplore.ieee.org/document/7993011</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="BLUR">[BLUR]</dt>
      <dd>
<span class="refAuthor">Kan, P.</span> and <span class="refAuthor">H. Kaufmann</span>, <span class="refTitle">"Physically-Based Depth of Field in Augmented Reality"</span>, <span class="refContent">Eurographics 2012 - Short Papers, pp. 89-92</span>, <span class="seriesInfo">DOI 10.2312/conf/EG2012/short/089-092</span>, <time datetime="2012" class="refDate">2012</time>, <span>&lt;<a href="https://diglib.eg.org/items/6954bf7e-5852-44cf-8155-4ba269dc4cee">https://diglib.eg.org/items/6954bf7e-5852-44cf-8155-4ba269dc4cee</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="CLOUD">[CLOUD]</dt>
      <dd>
<span class="refAuthor">Corneo, L.</span>, <span class="refAuthor">Eder, M.</span>, <span class="refAuthor">Mohan, N.</span>, <span class="refAuthor">Zavodovski, A.</span>, <span class="refAuthor">Bayhan, S.</span>, <span class="refAuthor">Wong, W.</span>, <span class="refAuthor">Gunningberg, P.</span>, <span class="refAuthor">Kangasharju, J.</span>, and <span class="refAuthor">J. Ott</span>, <span class="refTitle">"Surrounded by the Clouds: A Comprehensive Cloud Reachability Study"</span>, <span class="refContent">WWW '21: Proceedings of the Web Conference 2021, pp. 295-304</span>, <span class="seriesInfo">DOI 10.1145/3442381.3449854</span>, <time datetime="2021" class="refDate">2021</time>, <span>&lt;<a href="https://dl.acm.org/doi/10.1145/3442381.3449854">https://dl.acm.org/doi/10.1145/3442381.3449854</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="CWE">[CWE]</dt>
      <dd>
<span class="refAuthor">SANS Institute</span>, <span class="refTitle">"CWE/SANS TOP 25 Most Dangerous Software Errors"</span>, <span>&lt;<a href="https://www.sans.org/top25-software-errors/">https://www.sans.org/top25-software-errors/</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="DEV_HEAT_1">[DEV_HEAT_1]</dt>
      <dd>
<span class="refAuthor">LiKamWa, R.</span>, <span class="refAuthor">Wang, Z.</span>, <span class="refAuthor">Carroll, A.</span>, <span class="refAuthor">Lin, F.</span>, and <span class="refAuthor">L. Zhong</span>, <span class="refTitle">"Draining our glass: an energy and heat characterization of Google Glass"</span>, <span class="refContent">APSys '14: 5th Asia-Pacific Workshop on Systems, pp. 1-7</span>, <span class="seriesInfo">DOI 10.1145/2637166.2637230</span>, <time datetime="2014" class="refDate">2014</time>, <span>&lt;<a href="https://dl.acm.org/doi/10.1145/2637166.2637230">https://dl.acm.org/doi/10.1145/2637166.2637230</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="DEV_HEAT_2">[DEV_HEAT_2]</dt>
      <dd>
<span class="refAuthor">Matsuhashi, K.</span>, <span class="refAuthor">Kanamoto, T.</span>, and <span class="refAuthor">A. Kurokawa</span>, <span class="refTitle">"Thermal Model and Countermeasures for Future Smart Glasses"</span>, <span class="refContent">Sensors, vol. 20, no. 5, p. 1446</span>, <span class="seriesInfo">DOI 10.3390/s20051446</span>, <time datetime="2020" class="refDate">2020</time>, <span>&lt;<a href="https://www.mdpi.com/1424-8220/20/5/1446">https://www.mdpi.com/1424-8220/20/5/1446</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="DIST">[DIST]</dt>
      <dd>
<span class="refAuthor">Coulouris, G.</span>, <span class="refAuthor">Dollimore, J.</span>, <span class="refAuthor">Kindberg, T.</span>, and <span class="refAuthor">G. Blair</span>, <span class="refTitle">"Distributed Systems: Concepts and Design"</span>, <span class="refContent">Addison-Wesley</span>, <time datetime="2011" class="refDate">2011</time>, <span>&lt;<a href="https://dl.acm.org/doi/10.5555/2029110">https://dl.acm.org/doi/10.5555/2029110</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="EDGE_1">[EDGE_1]</dt>
      <dd>
<span class="refAuthor">Satyanarayanan, M.</span>, <span class="refTitle">"The Emergence of Edge Computing"</span>, <span class="refContent">Computer, vol. 50, no. 1, pp. 30-39</span>, <span class="seriesInfo">DOI 10.1109/MC.2017.9</span>, <time datetime="2017" class="refDate">2017</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/7807196">https://ieeexplore.ieee.org/document/7807196</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="EDGE_2">[EDGE_2]</dt>
      <dd>
<span class="refAuthor">Satyanarayanan, M.</span>, <span class="refAuthor">Klas, G.</span>, <span class="refAuthor">Silva, M.</span>, and <span class="refAuthor">S. Mangiante</span>, <span class="refTitle">"The Seminal Role of Edge-Native Applications"</span>, <span class="refContent">2019 IEEE International Conference on Edge Computing (EDGE), pp. 33-40</span>, <span class="seriesInfo">DOI 10.1109/EDGE.2019.00022</span>, <time datetime="2019" class="refDate">2019</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/8812200">https://ieeexplore.ieee.org/document/8812200</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="EDGE_3">[EDGE_3]</dt>
      <dd>
<span class="refAuthor">Peterson, L.</span> and <span class="refAuthor">O. Sunay</span>, <span class="refTitle">"5G Mobile Networks: A Systems Approach"</span>, <span class="refContent">Synthesis Lectures on Network Systems</span>, <span class="seriesInfo">DOI 10.1007/978-3-031-79733-0</span>, <time datetime="2020" class="refDate">2020</time>, <span>&lt;<a href="https://link.springer.com/book/10.1007/978-3-031-79733-0">https://link.springer.com/book/10.1007/978-3-031-79733-0</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="GLB_ILLUM_1">[GLB_ILLUM_1]</dt>
      <dd>
<span class="refAuthor">Kan, P.</span> and <span class="refAuthor">H. Kaufmann</span>, <span class="refTitle">"Differential Irradiance Caching for fast high-quality light transport between virtual and real worlds"</span>, <span class="refContent">2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp. 133-141</span>, <span class="seriesInfo">DOI 10.1109/ISMAR.2013.6671773</span>, <time datetime="2013" class="refDate">2013</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/6671773">https://ieeexplore.ieee.org/document/6671773</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="GLB_ILLUM_2">[GLB_ILLUM_2]</dt>
      <dd>
<span class="refAuthor">Franke, T.</span>, <span class="refTitle">"Delta Voxel Cone Tracing"</span>, <span class="refContent">2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp. 39-44</span>, <span class="seriesInfo">DOI 10.1109/ISMAR.2014.6948407</span>, <time datetime="2014" class="refDate">2014</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/6948407">https://ieeexplore.ieee.org/document/6948407</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="HEAVY_TAIL_1">[HEAVY_TAIL_1]</dt>
      <dd>
<span class="refAuthor">Crovella, M.</span> and <span class="refAuthor">B. Krishnamurthy</span>, <span class="refTitle">"Internet Measurement: Infrastructure, Traffic and Applications"</span>, <span class="refContent">John Wiley and Sons</span>, <time datetime="2006" class="refDate">2006</time>, <span>&lt;<a href="https://www.wiley.com/en-us/Internet+Measurement%3A+Infrastructure%2C+Traffic+and+Applications-p-9780470014615">https://www.wiley.com/en-us/Internet+Measurement%3A+Infrastructure%2C+Traffic+and+Applications-p-9780470014615</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="HEAVY_TAIL_2">[HEAVY_TAIL_2]</dt>
      <dd>
<span class="refAuthor">Taleb, N.</span>, <span class="refTitle">"Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications"</span>, <span class="refContent">Revised Edition, STEM Academic Press</span>, <time datetime="2022" class="refDate">2022</time>, <span>&lt;<a href="https://arxiv.org/pdf/2001.10488">https://arxiv.org/pdf/2001.10488</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="HEAVY_TAIL_3">[HEAVY_TAIL_3]</dt>
      <dd>
<span class="refAuthor">Ehrenberg, A.</span>, <span class="refTitle">"A Primer in Data Reduction: An Introductory Statistics Textbook"</span>, <span class="refContent">John Wiley and Sons</span>, <time datetime="2007" class="refDate">2007</time>, <span>&lt;<a href="https://www.wiley.com/en-us/A+Primer+in+Data+Reduction%3A+An+Introductory+Statistics+Textbook-p-9780471101352">https://www.wiley.com/en-us/A+Primer+in+Data+Reduction%3A+An+Introductory+Statistics+Textbook-p-9780471101352</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="LENS_DIST">[LENS_DIST]</dt>
      <dd>
<span class="refAuthor">Fuhrmann, A.</span>, <span class="refAuthor">Schmalstieg, D.</span>, and <span class="refAuthor">W. Purgathofer</span>, <span class="refTitle">"Practical Calibration Procedures for Augmented Reality"</span>, <span class="refContent">Virtual Environments 2000, pp. 3-12</span>, <span class="seriesInfo">DOI 10.1007/978-3-7091-6785-4_2</span>, <time datetime="2000" class="refDate">2000</time>, <span>&lt;<a href="https://link.springer.com/chapter/10.1007/978-3-7091-6785-4_2">https://link.springer.com/chapter/10.1007/978-3-7091-6785-4_2</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="METRICS_1">[METRICS_1]</dt>
      <dd>
<span class="refAuthor">ABI Research</span>, <span class="refTitle">"Augmented and Virtual Reality: The first Wave of Killer Apps: Qualcomm - ABI Research"</span>, <time datetime="2017-04" class="refDate">April 2017</time>, <span>&lt;<a href="https://gsacom.com/paper/augmented-virtual-reality-first-wave-5g-killer-apps-qualcomm-abi-research/">https://gsacom.com/paper/augmented-virtual-reality-first-wave-5g-killer-apps-qualcomm-abi-research/</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="METRICS_2">[METRICS_2]</dt>
      <dd>
<span class="refAuthor">Paxon, V.</span> and <span class="refAuthor">S. Floyd</span>, <span class="refTitle">"Wide area traffic: the failure of Poisson modeling"</span>, <span class="refContent">IEEE/ACM Transactions on Networking, vol. 3, no. 3, pp. 226-244</span>, <span class="seriesInfo">DOI 10.1109/90.392383</span>, <time datetime="1995-06" class="refDate">June 1995</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/392383">https://ieeexplore.ieee.org/document/392383</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="METRICS_3">[METRICS_3]</dt>
      <dd>
<span class="refAuthor">Willinger, W.</span>, <span class="refAuthor">Taqqu, M.S.</span>, <span class="refAuthor">Sherman, R.</span>, and <span class="refAuthor">D.V. Wilson</span>, <span class="refTitle">"Self-similarity through high variability: statistical analysis and Ethernet LAN traffic at source level"</span>, <span class="refContent">IEEE/ACM Transactions on Networking, vol. 5, no. 1, pp. 71-86</span>, <span class="seriesInfo">DOI 10.1109/90.554723</span>, <time datetime="1997-02" class="refDate">February 1997</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/abstract/document/554723">https://ieeexplore.ieee.org/abstract/document/554723</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="METRICS_4">[METRICS_4]</dt>
      <dd>
<span class="refAuthor">Gilbert, A.C.</span>, <span class="refTitle">"Multiscale Analysis and Data Networks"</span>, <span class="refContent">Applied and Computational Harmonic Analysis, vol. 10, no. 3, pp. 185-202</span>, <span class="seriesInfo">DOI 10.1006/acha.2000.0342</span>, <time datetime="2001-05" class="refDate">May 2001</time>, <span>&lt;<a href="https://www.sciencedirect.com/science/article/pii/S1063520300903427">https://www.sciencedirect.com/science/article/pii/S1063520300903427</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="METRICS_5">[METRICS_5]</dt>
      <dd>
<span class="refAuthor">Beyer, B., Ed.</span>, <span class="refAuthor">Jones, C., Ed.</span>, <span class="refAuthor">Petoff, J., Ed.</span>, and <span class="refAuthor">N.R. Murphy, Ed.</span>, <span class="refTitle">"Site Reliability Engineering: How Google Runs Production Systems"</span>, <span class="refContent">O'Reilly Media, Inc.</span>, <time datetime="2016" class="refDate">2016</time>, <span>&lt;<a href="https://research.google/pubs/site-reliability-engineering-how-google-runs-production-systems/">https://research.google/pubs/site-reliability-engineering-how-google-runs-production-systems/</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="METRICS_6">[METRICS_6]</dt>
      <dd>
<span class="refAuthor">Siriwardhana, Y.</span>, <span class="refAuthor">Porambage, P.</span>, <span class="refAuthor">Liyanage, M.</span>, and <span class="refAuthor">M. Ylianttila</span>, <span class="refTitle">"A Survey on Mobile Augmented Reality With 5G Mobile Edge Computing: Architectures, Applications, and Technical Aspects"</span>, <span class="refContent">IEEE Communications Surveys and Tutorials, vol. 23, no. 2, pp. 1160-1192</span>, <span class="seriesInfo">DOI 10.1109/COMST.2021.3061981</span>, <time datetime="2021" class="refDate">2021</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/9363323">https://ieeexplore.ieee.org/document/9363323</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="NIST1">[NIST1]</dt>
      <dd>
<span class="refAuthor">NIST</span>, <span class="refTitle">"Cloud Computing Synopsis and Recommendations"</span>, <span class="seriesInfo">NIST SP 800-146</span>, <span class="seriesInfo">DOI 10.6028/NIST.SP.800-146</span>, <time datetime="2012-05" class="refDate">May 2012</time>, <span>&lt;<a href="https://csrc.nist.gov/pubs/sp/800/146/final">https://csrc.nist.gov/pubs/sp/800/146/final</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="NIST2">[NIST2]</dt>
      <dd>
<span class="refAuthor">NIST</span>, <span class="refTitle">"Guide to General Server Security"</span>, <span class="seriesInfo">NIST SP 800-123</span>, <span class="seriesInfo">DOI 10.6028/NIST.SP.800-123</span>, <time datetime="2008-07" class="refDate">July 2008</time>, <span>&lt;<a href="https://csrc.nist.gov/pubs/sp/800/123/final">https://csrc.nist.gov/pubs/sp/800/123/final</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="NOISE">[NOISE]</dt>
      <dd>
<span class="refAuthor">Fischer, J.</span>, <span class="refAuthor">Bartz, D.</span>, and <span class="refAuthor">W. Strasser</span>, <span class="refTitle">"Enhanced visual realism by incorporating camera image effects"</span>, <span class="refContent">2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, pp. 205-208</span>, <span class="seriesInfo">DOI 10.1109/ISMAR.2006.297815</span>, <time datetime="2006" class="refDate">2006</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/4079277">https://ieeexplore.ieee.org/document/4079277</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="OCCL_1">[OCCL_1]</dt>
      <dd>
<span class="refAuthor">Breen, D.E.</span>, <span class="refAuthor">Whitaker, R.T.</span>, <span class="refAuthor">Rose, E.</span>, and <span class="refAuthor">M. Tuceryan</span>, <span class="refTitle">"Interactive Occlusion and Automatic Object Placement for Augmented Reality"</span>, <span class="refContent">Computer Graphics Forum, vol. 15, no. 3, pp. 11-22</span>, <span class="seriesInfo">DOI 10.1111/1467-8659.1530011</span>, <time datetime="1996-08" class="refDate">August 1996</time>, <span>&lt;<a href="https://onlinelibrary.wiley.com/doi/10.1111/1467-8659.1530011">https://onlinelibrary.wiley.com/doi/10.1111/1467-8659.1530011</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="OCCL_2">[OCCL_2]</dt>
      <dd>
<span class="refAuthor">Zheng, F.</span>, <span class="refAuthor">Schmalstieg, D.</span>, and <span class="refAuthor">G. Welch</span>, <span class="refTitle">"Pixel-wise closed-loop registration in video-based augmented reality"</span>, <span class="refContent">2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp. 135-143</span>, <span class="seriesInfo">DOI 10.1109/ISMAR.2014.6948419</span>, <time datetime="2014" class="refDate">2014</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/6948419">https://ieeexplore.ieee.org/document/6948419</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="OCCL_3">[OCCL_3]</dt>
      <dd>
<span class="refAuthor">Lang, B.</span>, <span class="refTitle">"Oculus Shares 5 Key Ingredients for Presence in Virtual Reality"</span>, <span class="refContent">Road to VR</span>, <time datetime="2014-09-24" class="refDate">24 September 2014</time>, <span>&lt;<a href="https://www.roadtovr.com/oculus-shares-5-key-ingredients-for-presence-in-virtual-reality/">https://www.roadtovr.com/oculus-shares-5-key-ingredients-for-presence-in-virtual-reality/</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="PER_SENSE">[PER_SENSE]</dt>
      <dd>
<span class="refAuthor">Mania, K.</span>, <span class="refAuthor">Adelstein, B.D.</span>, <span class="refAuthor">Ellis, S.R.</span>, and <span class="refAuthor">M.I. Hill</span>, <span class="refTitle">"Perceptual sensitivity to head tracking latency in virtual environments with varying degrees of scene complexity."</span>, <span class="refContent">APGV '04: Proceedings of the 1st Symposium on Applied perception in graphics and visualization, pp. 39-47</span>, <span class="seriesInfo">DOI 10.1145/1012551.1012559</span>, <time datetime="2004" class="refDate">2004</time>, <span>&lt;<a href="https://dl.acm.org/doi/10.1145/1012551.1012559">https://dl.acm.org/doi/10.1145/1012551.1012559</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="PHOTO_REG">[PHOTO_REG]</dt>
      <dd>
<span class="refAuthor">Liu, Y.</span> and <span class="refAuthor">X. Granier</span>, <span class="refTitle">"Online Tracking of Outdoor Lighting Variations for Augmented Reality with Moving Cameras"</span>, <span class="refContent">IEEE Transactions on Visualization and Computer Graphics, vol. 18, no. 4, pp. 573-580</span>, <span class="seriesInfo">DOI 10.1109/TVCG.2012.53</span>, <time datetime="2012" class="refDate">2012</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/6165138">https://ieeexplore.ieee.org/document/6165138</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="PREDICT">[PREDICT]</dt>
      <dd>
<span class="refAuthor">Buker, T.J.</span>, <span class="refAuthor">Vincenzi, D.A.</span>, and <span class="refAuthor">J.E. Deaton</span>, <span class="refTitle">"The effect of apparent latency on simulator sickness while using a see-through helmet-mounted display: reducing apparent latency with predictive compensation"</span>, <span class="refContent">Human Factors, vol. 54, no. 2, pp. 235-249</span>, <span class="seriesInfo">DOI 10.1177/0018720811428734</span>, <time datetime="2012-04" class="refDate">April 2012</time>, <span>&lt;<a href="https://pubmed.ncbi.nlm.nih.gov/22624290/">https://pubmed.ncbi.nlm.nih.gov/22624290/</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="REG">[REG]</dt>
      <dd>
<span class="refAuthor">Holloway, R.L.</span>, <span class="refTitle">"Registration Error Analysis for Augmented Reality"</span>, <span class="refContent">Presence: Teleoperators and Virtual Environments, vol. 6, no. 4, pp. 413-432</span>, <span class="seriesInfo">DOI 10.1162/pres.1997.6.4.413</span>, <time datetime="1997-08" class="refDate">August 1997</time>, <span>&lt;<a href="https://direct.mit.edu/pvar/article-abstract/6/4/413/18334/Registration-Error-Analysis-for-Augmented-Reality?redirectedFrom=fulltext">https://direct.mit.edu/pvar/article-abstract/6/4/413/18334/Registration-Error-Analysis-for-Augmented-Reality?redirectedFrom=fulltext</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC2210">[RFC2210]</dt>
      <dd>
<span class="refAuthor">Wroclawski, J.</span>, <span class="refTitle">"The Use of RSVP with IETF Integrated Services"</span>, <span class="seriesInfo">RFC 2210</span>, <span class="seriesInfo">DOI 10.17487/RFC2210</span>, <time datetime="1997-09" class="refDate">September 1997</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc2210">https://www.rfc-editor.org/info/rfc2210</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC2475">[RFC2475]</dt>
      <dd>
<span class="refAuthor">Blake, S.</span>, <span class="refAuthor">Black, D.</span>, <span class="refAuthor">Carlson, M.</span>, <span class="refAuthor">Davies, E.</span>, <span class="refAuthor">Wang, Z.</span>, and <span class="refAuthor">W. Weiss</span>, <span class="refTitle">"An Architecture for Differentiated Services"</span>, <span class="seriesInfo">RFC 2475</span>, <span class="seriesInfo">DOI 10.17487/RFC2475</span>, <time datetime="1998-12" class="refDate">December 1998</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc2475">https://www.rfc-editor.org/info/rfc2475</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC8939">[RFC8939]</dt>
      <dd>
<span class="refAuthor">Varga, B., Ed.</span>, <span class="refAuthor">Farkas, J.</span>, <span class="refAuthor">Berger, L.</span>, <span class="refAuthor">Fedyk, D.</span>, and <span class="refAuthor">S. Bryant</span>, <span class="refTitle">"Deterministic Networking (DetNet) Data Plane: IP"</span>, <span class="seriesInfo">RFC 8939</span>, <span class="seriesInfo">DOI 10.17487/RFC8939</span>, <time datetime="2020-11" class="refDate">November 2020</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc8939">https://www.rfc-editor.org/info/rfc8939</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC9023">[RFC9023]</dt>
      <dd>
<span class="refAuthor">Varga, B., Ed.</span>, <span class="refAuthor">Farkas, J.</span>, <span class="refAuthor">Malis, A.</span>, and <span class="refAuthor">S. Bryant</span>, <span class="refTitle">"Deterministic Networking (DetNet) Data Plane: IP over IEEE 802.1 Time-Sensitive Networking (TSN)"</span>, <span class="seriesInfo">RFC 9023</span>, <span class="seriesInfo">DOI 10.17487/RFC9023</span>, <time datetime="2021-06" class="refDate">June 2021</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9023">https://www.rfc-editor.org/info/rfc9023</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="RFC9450">[RFC9450]</dt>
      <dd>
<span class="refAuthor">Bernardos, CJ., Ed.</span>, <span class="refAuthor">Papadopoulos, G.</span>, <span class="refAuthor">Thubert, P.</span>, and <span class="refAuthor">F. Theoleyre</span>, <span class="refTitle">"Reliable and Available Wireless (RAW) Use Cases"</span>, <span class="seriesInfo">RFC 9450</span>, <span class="seriesInfo">DOI 10.17487/RFC9450</span>, <time datetime="2023-08" class="refDate">August 2023</time>, <span>&lt;<a href="https://www.rfc-editor.org/info/rfc9450">https://www.rfc-editor.org/info/rfc9450</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="SLAM_1">[SLAM_1]</dt>
      <dd>
<span class="refAuthor">Ventura, J.</span>, <span class="refAuthor">Arth, C.</span>, <span class="refAuthor">Reitmayr, G.</span>, and <span class="refAuthor">D. Schmalstieg</span>, <span class="refTitle">"A Minimal Solution to the Generalized Pose-and-Scale Problem"</span>, <span class="refContent">2014 IEEE Conference on Computer Vision and Pattern Recognition, pp. 422-429</span>, <span class="seriesInfo">DOI 10.1109/CVPR.2014.61</span>, <time datetime="2014" class="refDate">2014</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/6909455">https://ieeexplore.ieee.org/document/6909455</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="SLAM_2">[SLAM_2]</dt>
      <dd>
<span class="refAuthor">Sweeny, C.</span>, <span class="refAuthor">Fragoso, V.</span>, <span class="refAuthor">Höllerer, T.</span>, and <span class="refAuthor">M. Turk</span>, <span class="refTitle">"gDLS: A Scalable Solution to the Generalized Pose and Scale Problem"</span>, <span class="refContent">Computer Vision - ECCV 2014, pp. 16-31</span>, <span class="seriesInfo">DOI 10.1007/978-3-319-10593-2_2</span>, <time datetime="2014" class="refDate">2014</time>, <span>&lt;<a href="https://link.springer.com/chapter/10.1007/978-3-319-10593-2_2">https://link.springer.com/chapter/10.1007/978-3-319-10593-2_2</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="SLAM_3">[SLAM_3]</dt>
      <dd>
<span class="refAuthor">Gauglitz, S.</span>, <span class="refAuthor">Sweeney, C.</span>, <span class="refAuthor">Ventura, J.</span>, <span class="refAuthor">Turk, M.</span>, and <span class="refAuthor">T. Höllerer</span>, <span class="refTitle">"Model Estimation and Selection towards Unconstrained Real-Time Tracking and Mapping"</span>, <span class="refContent">IEEE Transactions on Visualization and Computer Graphics, vol. 20, no. 6, pp. 825-838</span>, <span class="seriesInfo">DOI 10.1109/TVCG.2013.243</span>, <time datetime="2014" class="refDate">2014</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/6636302">https://ieeexplore.ieee.org/document/6636302</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="SLAM_4">[SLAM_4]</dt>
      <dd>
<span class="refAuthor">Pirchheim, C.</span>, <span class="refAuthor">Schmalstieg, D.</span>, and <span class="refAuthor">G. Reitmayr</span>, <span class="refTitle">"Handling pure camera rotation in keyframe-based SLAM"</span>, <span class="refContent">2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp. 229-238</span>, <span class="seriesInfo">DOI 10.1109/ISMAR.2013.6671783</span>, <time datetime="2013" class="refDate">2013</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/6671783">https://ieeexplore.ieee.org/document/6671783</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="UBICOMP">[UBICOMP]</dt>
      <dd>
<span class="refAuthor">Bardram, J.</span> and <span class="refAuthor">A. Friday</span>, <span class="refTitle">"Ubiquitous Computing Systems"</span>, <span class="refContent">Ubiquitous Computing Fundamentals, 1st Edition, Chapman and Hall/CRC Press, pp. 37-94</span>, <time datetime="2009" class="refDate">2009</time>, <span>&lt;<a href="https://www.taylorfrancis.com/chapters/edit/10.1201/9781420093612-6/ubiquitous-computing-systems-jakob-bardram-adrian-friday">https://www.taylorfrancis.com/chapters/edit/10.1201/9781420093612-6/ubiquitous-computing-systems-jakob-bardram-adrian-friday</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="URLLC">[URLLC]</dt>
      <dd>
<span class="refAuthor">3GPP</span>, <span class="refTitle">"Study on enhancement of Ultra-Reliable Low-Latency Communication (URLLC) support in the 5G Core network (5GC)"</span>, <span class="seriesInfo">3GPP TR 23.725</span>, <time datetime="2019" class="refDate">2019</time>, <span>&lt;<a href="https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3453">https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3453</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="VIS_INTERFERE">[VIS_INTERFERE]</dt>
      <dd>
<span class="refAuthor">Kalkofen, D.</span>, <span class="refAuthor">Mendez, E.</span>, and <span class="refAuthor">D. Schmalstieg</span>, <span class="refTitle">"Interactive Focus and Context Visualization for Augmented Reality"</span>, <span class="refContent">2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, pp. 191-201</span>, <span class="seriesInfo">DOI 10.1109/ISMAR.2007.4538846</span>, <time datetime="2007" class="refDate">2007</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/4538846">https://ieeexplore.ieee.org/document/4538846</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="XR">[XR]</dt>
      <dd>
<span class="refAuthor">3GPP</span>, <span class="refTitle">"Extended Reality (XR) in 5G"</span>, <span class="seriesInfo">3GPP TR 26.928</span>, <time datetime="2020" class="refDate">2020</time>, <span>&lt;<a href="https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3534">https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3534</a>&gt;</span>. </dd>
<dd class="break"></dd>
<dt id="XR_TRAFFIC">[XR_TRAFFIC]</dt>
    <dd>
<span class="refAuthor">Apicharttrisorn, K.</span>, <span class="refAuthor">Balasubramanian, B.</span>, <span class="refAuthor">Chen, J.</span>, <span class="refAuthor">Sivaraj, R.</span>, <span class="refAuthor">Tsai, Y.</span>, <span class="refAuthor">Jana, R.</span>, <span class="refAuthor">Krishnamurthy, S.</span>, <span class="refAuthor">Tran, T.</span>, and <span class="refAuthor">Y. Zhou</span>, <span class="refTitle">"Characterization of Multi-User Augmented Reality over Cellular Networks"</span>, <span class="refContent">2020 17th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON), pp. 1-9</span>, <span class="seriesInfo">DOI 10.1109/SECON48991.2020.9158434</span>, <time datetime="2020" class="refDate">2020</time>, <span>&lt;<a href="https://ieeexplore.ieee.org/document/9158434">https://ieeexplore.ieee.org/document/9158434</a>&gt;</span>. </dd>
<dd class="break"></dd>
</dl>
</section>
<div id="ack">
<section id="appendix-A">
      <h2 id="name-acknowledgements">
<a href="#name-acknowledgements" class="section-name selfRef">Acknowledgements</a>
      </h2>
<p id="appendix-A-1">Many thanks to <span class="contact-name">Spencer Dawkins</span>, <span class="contact-name">Rohit Abhishek</span>, <span class="contact-name">Jake Holland</span>,
        <span class="contact-name">Kiran Makhijani</span>, <span class="contact-name">Ali         Begen</span>, <span class="contact-name">Cullen Jennings</span>, <span class="contact-name">Stephan Wenger</span>, <span class="contact-name">Eric Vyncke</span>,
        <span class="contact-name">Wesley Eddy</span>, <span class="contact-name">Paul Kyzivat</span>,
        <span class="contact-name">Jim Guichard</span>, <span class="contact-name">Roman         Danyliw</span>, <span class="contact-name">Warren Kumari</span>, and <span class="contact-name">Zaheduzzaman Sarker</span> for providing helpful feedback,
        suggestions, and comments.<a href="#appendix-A-1" class="pilcrow">¶</a></p>
</section>
</div>
<div id="authors-addresses">
<section id="appendix-B">
      <h2 id="name-authors-addresses">
<a href="#name-authors-addresses" class="section-name selfRef">Authors' Addresses</a>
      </h2>
<address class="vcard">
        <div dir="auto" class="left"><span class="fn nameRole">Renan Krishna</span></div>
<div dir="auto" class="left"><span class="country-name">United Kingdom</span></div>
<div class="email">
<span>Email:</span>
<a href="mailto:renan.krishna@gmail.com" class="email">renan.krishna@gmail.com</a>
</div>
</address>
<address class="vcard">
        <div dir="auto" class="left"><span class="fn nameRole">Akbar Rahman</span></div>
<div dir="auto" class="left"><span class="org">Ericsson</span></div>
<div dir="auto" class="left"><span class="street-address">349 Terry Fox Drive</span></div>
<div dir="auto" class="left">
<span class="locality">Ottawa</span> <span class="region">Ontario</span> <span class="postal-code">K2K 2V6</span>
</div>
<div dir="auto" class="left"><span class="country-name">Canada</span></div>
<div class="email">
<span>Email:</span>
<a href="mailto:Akbar.Rahman@ericsson.com" class="email">Akbar.Rahman@ericsson.com</a>
</div>
</address>
</section>
</div>
<script>const toc = document.getElementById("toc");
toc.querySelector("h2").addEventListener("click", e => {
  toc.classList.toggle("active");
});
toc.querySelector("nav").addEventListener("click", e => {
  toc.classList.remove("active");
});
</script>
</body>
</html>
